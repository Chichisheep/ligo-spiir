#!/usr/bin/env python
#
# Copyright (C) 2011 Chris Pankow
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
"""Stream-based burst analysis tool"""

#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


import os
import numpy
import signal

from optparse import OptionParser
from ConfigParser import SafeConfigParser

from gstlal.pipeutil import gst, mkelem
from gstlal.pipeparts import *
from gstlal.pipeio import parse_spectrum_message
from gstlal.lloidparts import LLOIDHandler

import gstlal.excesspower as ep
from gstlal.excesspower import *

from glue.ligolw import ligolw
from glue.ligolw import lsctables
from glue.ligolw import utils

from pylal.xlal.datatypes.snglburst import from_buffer as sngl_bursts_from_buffer
from pylal.xlal.datatypes.real8frequencyseries import REAL8FrequencySeries

#
# =============================================================================
#
#                                Handler Class
#
# =============================================================================
#


class EPHandler( LLOIDHandler ):
	"""
	Handler class for the excess power pipeline. Keeps various bits of information that the pipeline emits and consumes. This is also in charge of signalling the rebuild of various matrices and vectors needed by the pipeline.
	"""
	def __init__( self, mainloop, pipeline ):
		# Defaults
		self.base_band = 16
		self.flow = 64 
		self.fhigh = 1000
		#self.fhigh = 2000
		self.rate = 2048
		#self.rate = 4096
		self.filter_len = 2*int(2*self.rate/self.base_band)

		self.max_level = 1

		self.psd = self.build_default_psd( self.rate, self.filter_len )
		self.psd_power = 0

		self.spec_corr = self.build_default_correlation( self.rate )

		self.filter_bank = None
		# TODO: Maybe not necessary
		self.rebuild_filter()
		self.firbank = None

		self.chan_matrix = None
		self.rebuild_chan_mix_matrix()
		self.mmixers = {}

		self.unicorns = False

		self.output = None
		self.triggers = None
		self.outfile = "test.xml"
		self.make_output_table()

		self.cache_psd = False
		self.cache_spec_corr = False

		self.snr_thresh = 5.5

		super(type(self), self).__init__(mainloop, pipeline)

	def add_firbank( self, firbank ):
		"""
		Set the main base band FIR bank, and build the FIR matrix.
		"""
		self.firbank = firbank
		firbank.set_property( "fir-matrix", self.rebuild_filter() )

	def add_matmixer( self, mm, res_level ):
		self.mmixers[ res_level ] = mm
		self.rebuild_matrix_mixers( res_level )

	def build_default_psd( self, rate, filter_len ):
		"""
		Builds a dummy PSD to use until we get the right one.
		"""
		psd = REAL8FrequencySeries()
		psd.deltaF = float(rate)/filter_len
		psd.data = numpy.ones( filter_len/2 + 1 ) #/ 2 / psd.deltaF
		psd.f0 = 0
		return psd

	def build_default_correlation( self, rate ):
		"""
		Builds a Kronecker delta correlation series for k, k'.
		"""
		corr = numpy.zeros(rate + 1)
		corr[0] = 1
		return corr

	def rebuild_matrix_mixers( self, res_level = None ):
		"""
		Rebuilds the matrix mixer matrices from the coefficients calculated in rebuild_chan_mix_matrix and assigns them to their proper element.
		"""
		for i, mm in self.mmixers.iteritems():
			if( res_level != None and res_level != i ): continue

			nchannels = self.filter_bank.shape[0]
			up_factor = int(numpy.log2(nchannels/(nchannels >> i)))
			cmatrix = ep.build_chan_matrix( 
				nchannels = nchannels,
				up_factor = up_factor,
				norm = self.chan_matrix[i] 
			)
			mm.set_property( "matrix", cmatrix )

	def rebuild_filter( self ):
		"""
		Calling this function rebuilds the filter FIR banks and assigns them to their proper element. This is normally called when the PSD or spectrum correlation changes.
		"""
		self.filter_bank = ep.build_filter( fhigh = self.fhigh, psd = self.psd, corr = self.spec_corr, b_wind = self.base_band )
		return self.filter_bank

	def build_filter_xml( self, res_level, loc="" ):
		"""
		Calls the EP library to create a XML of sngl_burst tables representing the filter banks. At the moment, this dumps them to the current directory, but this can be changed by supplying the 'loc' argument. The written filename is returned for easy use by the trigger generator.
		"""
		xmldoc = ep.create_bank_xml(
			self.flow,
			self.fhigh,
			self.base_band,
			# TODO; Check duration, should this go up by factors of two?
			len(self.filter_bank[0])/self.rate
			#TODO: self.detector
		)
		output = "%sgstlal_excesspower_bank_level_%d.xml" % (loc, res_level)
		utils.write_filename(xmldoc, output, verbose = True,
		       gz = (output or "stdout").endswith(".gz"))
		return output

	def rebuild_chan_mix_matrix( self ):
		"""
		Calling this function rebuilds the matrix mixer coefficients for higher resolution components. This is normally called when the PSD or spectrum correlation changes.
		"""
		self.chan_matrix = ep.build_inner_product_norm( 
			corr = self.spec_corr, 
			band = self.base_band, 
			del_f = self.psd.deltaF,
			nfilts = len(self.filter_bank),
			flow = self.flow,
			# TODO: PSD option to lalburst IP doesn't work
			#psd = self.psd
			max_level = self.max_level
		)
		return self.chan_matrix

	def rebuild_everything( self ):
		"""
		Top-level function to handle the asynchronous updating of FIR banks and matrix mixer elements.
		"""
		# Rebuild filter bank and hand it off to the FIR element
		print >> sys.stderr, "Rebuilding FIR bank"
		self.firbank.set_property( "fir_matrix", self.rebuild_filter() )

		print >> sys.stderr, "Rebuilding matrix mixer"
		self.rebuild_chan_mix_matrix()
		# Rebuild the matrix mixer with new normalization coefficients
		self.rebuild_matrix_mixers()

	def make_output_table( self ):
		self.triggers = lsctables.New(lsctables.SnglBurstTable,
			["ifo", "peak_time", "start_time", 
			"duration",  "search",
			"central_freq", "channel", "amplitude", "snr", "confidence",
			"chisq", "chisq_dof", "bandwidth"])
			#"peak_frequency",
			#"stop_time", "peak_time_ns", "start_time_ns", "stop_time_ns",
 			#"time_lag", "flow", "fhigh", tfvolume, hrss, process_id
		return self.triggers

	def write_triggers( self, flush=True ):
		output = ligolw.Document()
		output.appendChild(ligolw.LIGO_LW())
		output.childNodes[0].appendChild( self.triggers )
		utils.write_filename(output, self.outfile, verbose = options.verbose)
	         #gz = (output or "stdout").endswith(".gz"))
		if( flush ): self.make_output_table()

	def shutdown( self, signum, frame ):
		"""
		Method called to flush buffers and shutdown the pipeline.
		"""
		print >>sys.stderr, "Caught signal. Dying a terrible, terrible death."
		self.write_triggers( False )
		bus = self.pipeline.get_bus()
		bus.post(gst.message_new_eos(pipeline))
		self.pipeline.set_state( gst.STATE_NULL )
		self.mainloop.quit()

#
# =============================================================================
#
#                        Message Handler Methods
#
# =============================================================================
#

# These are linked later in the pipeline to do the appropriate actions when signals are sent up.

def on_psd_change( elem, pspec, hand ):
	"""
	Get the PSD object and signal the handler to rebuild everything.
	"""
	print >> sys.stderr, "Intercepted spectrum signal."
	# TODO: Ensure that the other options (flow and such) are set here as well

	hand.psd = REAL8FrequencySeries(
		name = "PSD",
		#epoch = laltypes.LIGOTimeGPS(0, message.structure["timestamp"]),
		f0 = 0.0,
		deltaF = elem.get_property( "delta-f" ),
		#sampleUnits = laltypes.LALUnit(message.structure["sample-units"].strip()),
		data = numpy.array( elem.get_property( "mean-psd" ) )
	)

	if( hand.cache_psd ):
		f = open("psd.dat", "w")
		for freq, p in enumerate( hand.psd.data ):
			f.write("%f %g\n" % (freq*hand.psd.deltaF, p) )
		f.close()

	# Determine if the PSD has changed enough to warrant rebuilding the filter
	# bank.
	psd_power = sum(hand.psd.data)
	change = abs((hand.psd_power - psd_power) / psd_power )
	if( change > 0.5 ):
		print >> sys.stderr, "Processed signal. PSD change %d per, regenerating filters" % int(change*100)
		hand.psd_power = psd_power
		hand.rebuild_everything()

def on_spec_corr_change( elem, pspec, hand ):
	"""
	Get the 2-point spectral correlation object and signal the handler to rebuild everything.
	"""
	print >> sys.stderr, "Intercepted correlation signal."
	hand.spec_corr = elem.get_property( "spectral-correlation" )

	if( hand.cache_spec_corr ):
		f = open( "spec_corr.dat", "w" )
		k_end = len( hand.spec_corr ) / 2
		for k, sp in enumerate( hand.spec_corr ):
			f.write( "%d %g\n" % (k, sp) )
	
	# If the spectrum correlation changes, rebuild everything
	if( hand.psd != None ):
		hand.rebuild_everything()

#
# =============================================================================
#
#                             Options Handling
#
# =============================================================================
#

parser = OptionParser()
parser.add_option("-f", "--initialization-file", dest="infile", help="Options to be pased to the pipeline handler. Strongly recommended.", default=None)
parser.add_option("-d", "--diagnostics", dest="diagnostics", action="store_true", help="Turn on multiple diagnostic dumps. Use with caution, as it will dump gigabytes of data (potentially) in a matter of minutes. Useful in nongraphical environemnts to monitor data throughput.", default=False)
parser.add_option("-v", "--verbose", dest="verbose", action="store_true", help="Be verbose.", default=False)
parser.add_option("-s", "--sample-rate", dest="sample_rate", action="store", type="int", help="Sample rate of the incoming data. Required only if a fake data source is being used.")
parser.add_option("--data-source", dest="data_source", action="store", help="Data source to read from. Valid options are gwffile,lldata,whitedata,fakeLIGO,fakeadvLIGO. One is required. If gwffile is selected, then a cache file should also be provided. If whitedata, fakeLIGO, or fakeadvLIGO is selected, then a sample rate must also be provided.")
parser.add_option("--unicorns", dest="unicorns", action="store", type="float", help="Reveal hidden unicorns in data. The argument to this option determines how strong said unicorns are.", default=None)

(options, args) = parser.parse_args()

# The data rate at which we wish to do analysis
# Assumed lower than the input data
data_source = options.data_source
valid_data_sources = [ "gwffile", 
	  "lldata", 
	  "whitedata", 
	  "fakeLIGO", 
	  "fakeadvLIGO" ]
if( not data_source in valid_data_sources ):
	print >>sys.stderr, "Either no data soruce was selected, or an invalid one was requested."
	sys.exit(-1)

if( not options.sample_rate 
	and ( data_source in ["whitedata", "fakeLIGO", "fakeadvLIGO"] ) ):
	print >>sys.stderr, "Sample rate not specified and fake data requested."
	sys.exit(-1)
else:
	sample_rate = options.sample_rate
	# TODO: Unhardcode this
	sample_rate = 2048

# Verbosity and diagnostics
verbose = options.verbose
diagnostics = options.diagnostics

# UNICORNS!!!!!!!!!!11!
if( options.unicorns ):
	unicorns = True
	unicorn_volume = options.unicorns 
	unicorn_volume = 1e-18
else: unicorns = False

##### HANDLER / PIPELINE OPTIONS ############

pipeline = gst.Pipeline( "gstlal_excesspower" )
mainloop = gobject.MainLoop()
handler = EPHandler(mainloop, pipeline)

if( not options.infile ):
	print >>sys.stderr, "No initialization file specified. Default values will be used."
else:
	cfg = SafeConfigParser()
	cfg.read( options.infile )

	# Handler options
	handler.flow = cfg.getint( "tf_parameters", "min-frequency" )
	handler.fhigh = cfg.getint( "tf_parameters", "max-frequency" )
	handler.base_band = cfg.getint( "tf_parameters", "base-resolution" )
	handler.max_level = cfg.getint( "tf_parameters", "max-resolution-level" )
	handler.max_duration = cfg.getfloat( "tf_parameters", "max-time-resolution" )
	handler.cache_spec_corr = cfg.getboolean(
					"cache", "cache-spectral-correlation" )
	handler.cache_psd = cfg.getboolean( 
					"cache", "cache-psd" )

	handler.snr_thresh = cfg.getfloat( "triggering", "snr-thresh" )

	# Detector
	inst = cfg.get( "instrument", "detector" )

	#inj_loc = "injections/burst_injections.xml"
	#inj_loc = "injections/sg.xml"
	inj_loc = cfg.get( "injections", "xml-location" )
	inj_loc = "injections/sc.xml"

base_band = handler.base_band

# Max trigger duration (s)
max_dur = handler.max_duration
max_dur = 1  # s

#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#

if options.verbose:
	print >>sys.stderr, "Assembling pipeline...",

# Data source
# TODO: Unhardcode this after testing
if( data_source == "fakeLIGO" ):
	head = mkfakeLIGOsrc( pipeline, instrument="H1", channel_name = "LSC-STRAIN" )
elif( data_source == "fakeadvLIGO" ):
	head = mkfakeadvLIGOsrc( pipeline, instrument="H1", channel_name = "LSC-STRAIN" )
elif( data_source == "whitedata" ):
	head = gst.element_factory_make( "audiotestsrc" )
	pipeline.add( head )
	head.set_property( "wave", 9 )
elif( data_source == "lldata" ):
	# TODO: This
	print >>sys.stderr, "Not implemented yet. :( Tell Chris to stop being so damn lazy."
	sys.exit(-1)
elif( data_source == "gwffile" ):
	# TODO: This
	print >>sys.stderr, "Not implemented yet. :( Tell Chris to stop being so damn lazy."
	sys.exit(-1)

# TODO: Scheduled for deletion
#def on_new_pad(dbin, pad, islast):
	#decode = pad.get_parent()
	#pipeline = decode

# Diagnostic plot
if( diagnostics ):
	head = postdatatee = mktee( pipeline, head )
	mknxydumpsink( pipeline, mkqueue( pipeline, postdatatee ), "data_pre.txt" )

"""
def on_new_decoded_pad(dbin, pad, islast):
	decode = pad.get_parent()
	pipeline = decode.get_parent()
	convert = pipeline.get_by_name('audioconvert0')
	decode.link(convert)
	pipeline.set_state(gst.STATE_PLAYING)
	print "linked!"

	#inj_head = mkgeneric( pipeline, inj_head, "decodebin2" )
	#inj_head.connect( "new-decoded-pad", on_new_decoded_pad )
	#convert = gst.element_factory_make( "audioconvert" )
	#pipeline.add( convert )
	#inj_head = mkgeneric( pipeline, inj_head, "wavparse" )
"""

# Data conditioning
# TODO: Does this need to be set if the data source isn't fake?
head = mkcapsfilter( pipeline, mkresample( pipeline, head ), "audio/x-raw-float,rate=%d" % sample_rate )

#if( unicorns ):
if( True ):
	unicorn_volume = 1e-20
	inj_head = gst.element_factory_make( "filesrc" )
	pipeline.add( inj_head )
	inj_head.set_property( "location" , "/Users/chrispankow/work/codedev/excesspower/pipeline/jolien/unicorn1_delay.mp3" )
	inj_head = mkgeneric( pipeline, inj_head, "mad" )
	inj_head = mkaudioconvert( pipeline, inj_head )
	inj_head = mkresample( pipeline, inj_head ) 
	inj_head = mkcapsfilter( pipeline, inj_head, "audio/x-raw-float,channels=1,width=64,rate=%d" % sample_rate )
	inj_head = mkgeneric( pipeline, inj_head, "audioamplify" )
	inj_head.set_property( "amplification", unicorn_volume )
	#inj_head = inj_tee = mktee( pipeline, inj_head )
	#mknxydumpsink( pipeline, mkqueue( pipeline, inj_tee ), "unicorn_delay.txt" )
	adder = mkgeneric( pipeline, inj_head, "lal_adder" )
	adder.set_property( "sync", True )
	head.link( adder )
	head = adder

#if( inj_loc ):
if( False ):
	head = mkinjections( pipeline, head, inj_loc )
	head = mkprogressreport( pipeline, head, "post injection" )

head = whitener = mkwhiten( pipeline, head )
head = mknofakedisconts( pipeline, head )

# Diagnostic plot
if( diagnostics ):
	head = postresamptee = mktee( pipeline, head )
	mknxydumpsink( pipeline, mkqueue( pipeline, head ), "data_post.txt" )

head = mkprogressreport( pipeline, head, "post whitener" )

# excess power channel firbank
# NOTE: This is where the inspiral pipeline will feed in?
head = mkfirbank( pipeline, head, time_domain=False )

# TODO: Make this less hardcodish
handler.add_firbank( pipeline.get_by_name( "gstlalfirbank0" ) )
nchannels = handler.filter_bank.shape[0]

# TODO: We could limit the number of resolutions available and add an
# audioundersampler here to reduce our workload, for each factor of
# undersampling, we reduce our largest available frequency tile by a factor of 
# 2.

head = mkprogressreport( pipeline, head, "post FIR bank" )

head = postfirtee = mktee( pipeline, mkqueue( pipeline, head ) )
# Diagnostic plot
if( diagnostics ):
	mknxydumpsink( pipeline, postfirtee, "postfirbank.txt" )

# First branch -- send fully sampled data to wider channels for processing
nlevels = int(numpy.ceil( numpy.log2( nchannels ) )) 
for res_level in range(0, min(handler.max_level, nlevels)):
	head = postfirtee

	head = matmixer = mkmatrixmixer( pipeline, head )
	handler.add_matmixer( matmixer, res_level )

	head = mkprogressreport( pipeline, head, "post matrix mixer %d" % res_level )

	head = postmmtee = mktee( pipeline, mkqueue( pipeline, head ) )
	mknxydumpsink( pipeline, postmmtee, "postmatmix_res_%d.txt" % res_level )

	# TODO: Make this into an option
	#import ep_visualization as vis
	#if( res_level == 0 ):
		#vis.channelgram( pipeline, postmmtee )
	
	elem = gst.element_factory_make("lal_audioundersample")

	pipeline.add(elem)
	head.link(elem)
	head = elem

	# base_band * 2 * # of channel combinations
	band = base_band * 2**res_level
	chan = numpy.ceil( nchannels / 2.0**res_level )

	# 2B = Nyquist = sample rate
	undersamp_rate = sample_rate >> res_level
	head = mkcapsfilter( pipeline, head, "audio/x-raw-float,rate=%d,width=64,channels=%d" % (undersamp_rate, chan) )

	head = postustee = mktee( pipeline, mkqueue( pipeline, head ) )
	mknxydumpsink( pipeline, postustee, "postundersamp_res_%d.txt" % res_level )

	elem = gst.element_factory_make("pow")
	elem.set_property( "exponent", 2 )
	pipeline.add(elem)
	head.link(elem)
	head = elem

	head = mktee( pipeline, head )

	duration = 1
	# Second branch -- duration
	# max_samp = int(max_dur*rate)
	#while duration <= max_samp:
		#duration = duration << 1

	# Multi channel FIR filter
	elem = gst.element_factory_make("audiofirfilter")
	# TODO: Calculate the right thing here
	fir_sq_adder = ep.build_fir_sq_adder( duration )
	elem.set_property( "kernel", fir_sq_adder )
	pipeline.add(elem)
	head.link(elem)
	head = elem

	"""
	head = postsqtee = mktee( pipeline, mkqueue( pipeline, head ) )
	mknxydumpsink( pipeline, postsqtee, "postsquare_ts_%d.txt" % duration )

	head = mkprogressreport( pipeline, head, "post audio FIR filter %d, %d" % (res_level, duration) )
	"""

	# TODO: Create new filter banks for each level
	#head = mkbursttriggergen( pipeline, head, 1, bank = "banks/full_bank.xml" )
	head = mkbursttriggergen( pipeline, head, 1, 
		bank = handler.build_filter_xml( res_level )
	)
	head.set_property( "snr-thresh", handler.snr_thresh )

	head = mkprogressreport( pipeline, head, "post trigger gen %d, %d" % (res_level, duration) )

	#head = mkfakesink( pipeline, head )

# TODO: This will have to be in the higher level loop
# generate triggers
def get_triggers(elem, handler):
	for row in sngl_bursts_from_buffer(elem.emit("pull-buffer")):
		handler.triggers.append( row )
appsink = mkappsink(pipeline, mkqueue(pipeline, head))
appsink.connect_after("new-buffer", get_triggers, handler)

# Spectrum notification processing
whitener.connect_after( "notify::mean-psd", on_psd_change, handler )
# Handle spectral correlation changes
# TODO: Make sure this doesn't have to be in the mm loop
whitener.connect_after( "notify::spectral-correlation", on_spec_corr_change, handler )

# Handle shutdowns
signal.signal( signal.SIGINT, handler.shutdown )
signal.signal( signal.SIGTERM, handler.shutdown )

print >>sys.stderr, "Startin' up."
pipeline.set_state( gst.STATE_PLAYING )
gst.DEBUG_BIN_TO_DOT_FILE(pipeline,
		gst.DEBUG_GRAPH_SHOW_ALL,"excesspower.dotfile")
mainloop.run()

