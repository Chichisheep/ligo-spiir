#!/usr/bin/python

# FIXME proper copyright and GPL notice
# Copyright 2011 Kipp Cannon, Chad Hanna
#import matplotlib
#matplotlib.use('Agg')
#import pylab

import sys
import numpy
from scipy import interpolate, random
from scipy.stats import poisson
from glue.ligolw import lsctables
from glue.ligolw import utils
from glue.ligolw.utils import process as ligolw_process
from glue.ligolw.utils import segments as ligolw_segments
from glue.segmentsUtils import vote
from pylal import inject
from pylal import rate
from optparse import OptionParser
from gstlal import inspiral as gstlal_likelihood
from gstlal.svd_bank import read_bank
from gstlal import far

try:
	import sqlite3
except ImportError:
	# pre 2.5.x
	from pysqlite2 import dbapi2 as sqlite3

sqlite3.enable_callback_tracebacks(True)


def parse_command_line():
	parser = OptionParser()
	parser.add_option("--background-bins-file", metavar = "filename", action = "append", help = "Set the name of the xml file containing the snr / chisq background distributions")
	parser.add_option("--segments-file", metavar = "filename", help = "Set the name of the xml file containing analysis segments.")
	parser.add_option("--segments-name", metavar = "name", default = "datasegments", help = "Set the name of the analysis segments (default = 'datasegments').")
	parser.add_option("--vetoes-file", metavar = "filename", help = "Set the name of the xml file containing the veto segments.")
	parser.add_option("--vetoes-name", metavar = "name", default = "vetoes", help = "Set the name of the vetoes segments (default = 'vetoes').")
	parser.add_option("--additional-trials-factor", metavar = "int", type="int", default=1, help = "set an additional trials factor to apply to the FAP.  Default = 1 (no trials factor)")
	parser.add_option("--tmp-space", metavar = "dir", help = "Set the name of the tmp space if working with sqlite")
	parser.add_option("--compute-fap", action = "store_true", help = "compute fap, otherwise compute far assuming fap has been calculated")
	parser.add_option("--compute-far", action = "store_true", help = "compute far, only works if fap is being computed or has been computed.")
	parser.add_option("--verbose", "-v", action = "store_true", help = "Be verbose.")
	parser.add_option("--non-injection-db", help = "single file for non injections run")
	parser.add_option("--injection-dbs", action = "append", default=[], help = "append to the list of possible injection files, may be empty if no injections were done. Databases are assumed to be over the same time period as the non injection databases using the same templates.  If not the results will be nonsense.")

	options, filenames = parser.parse_args()
	return options, filenames

#
# Parse command line
#

options, filenames = parse_command_line()

#
# load segment data
#

segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.segments_file, verbose = options.verbose), options.segments_name).coalesce()
vetoes = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.vetoes_file, verbose = options.verbose), options.vetoes_name).coalesce()

#
# Here we get the union of all of the possible live time segments and subtract
# the vetoes.
#

segments -= vetoes
livetime = far.get_live_time(segments)

#
# Pull out background and injections distribution
#

if options.compute_fap:
	# retrieve rank data
	coincparamsdistributions, likelihood_seglists = gstlal_likelihood.load_likelihood_data(options.background_bins_file, verbose = options.verbose)
	injections = coincparamsdistributions.injection_rates
	far.populate_injections(injections)
	counts = coincparamsdistributions.background_rates
	Far = far.FAR(livetime, options.additional_trials_factor, counts, injections)
else:
	Far = far.FAR(livetime, options.additional_trials_factor)

# late import for DB manipulations
from glue.ligolw import dbtables

#
# remove zero lag from bins if we are computing faps
#

if options.compute_fap is not None:

	working_filename = dbtables.get_connection_filename(options.non_injection_db, tmp_path = options.tmp_space, verbose = options.verbose)
	connection = sqlite3.connect(working_filename)

	# remove zero lag triggers from the background bins
	# FIXME this is supposed to pull out only triggers found in zero lag, is it correct?
	if options.verbose:
		print >>sys.stderr, "num sngl trigs before", " ".join(["%s:%d" % (ifo, cnts.array.sum()) for (ifo, cnts) in Far.counts.items()])

	for ifo, snr, chisq in connection.cursor().execute("SELECT ifo, snr, chisq FROM sngl_inspiral WHERE sngl_inspiral.event_id IN (SELECT event_id FROM coinc_event_map JOIN coinc_event ON (coinc_event_map.table_name == 'sngl_inspiral' AND coinc_event.coinc_event_id == coinc_event_map.coinc_event_id) WHERE NOT EXISTS (SELECT * FROM time_slide WHERE time_slide.time_slide_id == coinc_event.time_slide_id AND time_slide.offset != 0))"):
		Far.counts[ifo+"_snr_chi"][snr, chisq**.5 / snr] -= 1

	if options.verbose:
		print >>sys.stderr, "num sngl trigs after", " ".join(["%s:%d" % (ifo, cnts.array.sum()) for (ifo, cnts) in Far.counts.items()])

	Far.set_trials_table(connection)
	
	connection.close()
	dbtables.discard_connection_filename(options.non_injection_db, working_filename, verbose = options.verbose)

#
# Compute the likelihood ratio
#

# FIXME:  the smoothing should be done with the .finish() method.
# FIXME:  make sure the smoothing is what is intended:  what's coded here
# is neither computing a sliding average of bin counts, nor an event rate
# density.
#coincparamsdistributions.finish(filters = gstlal_likelihood.DistributionsStats.filters, verbose = options.verbose)

if options.compute_fap:
	print >>sys.stderr, "smoothing bin counts and computing likelihood ..."
	minvals = []
	for i, k in enumerate(Far.counts):
		binned_array = Far.counts[k]
		far.smooth_bins(binned_array)
		binned_array = Far.injections[k]
		far.smooth_bins(binned_array)
		# FIXME inverse likelihood is what is used for the ranking, small means likely
		Far.counts[k].array /= Far.injections[k].array
		# we want Nans to be inf because they are not likely to be a GW
		Far.counts[k].array[numpy.isnan(Far.counts[k].array)] = float('inf')
		# normalize so that the max value is always less than one
		Far.counts[k].array /= Far.counts[k].array[-numpy.isinf(Far.counts[k].array)].sum()
		minArr = Far.counts[k].array[Far.counts[k].array != 0.0]
		if len(minArr) > 0:
			minvals.append(minArr.min())
	minval = min(minvals)
	rankoffset = numpy.ceil(numpy.abs(numpy.log(minval))) + 1

#
# iterate over files to rank
#

if options.compute_fap is not None:
	far.set_fap(options, Far, options.non_injection_db, rankoffset)
	# increment the trials factor by 1 before assigning faps for
	# injections.  Injections imply that there is always one more event
	Far.increment_trials_table(1)
	for f in options.injection_dbs:
		far.set_fap(options, Far, f, rankoffset)

if options.compute_far is not None:
	far.set_far(options, Far, options.non_injection_db)
	for f in options.injection_dbs:
		far.set_far(options, Far, f)
