#!/usr/bin/env python
#
# Copyright (C) 2009-2011  Kipp Cannon, Chad Hanna, Drew Keppel
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
"""Stream-based inspiral analysis tool"""


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


import os
import sys
import threading
import warnings
from optparse import OptionParser


# The following snippet is taken from http://gstreamer.freedesktop.org/wiki/FAQ#Mypygstprogramismysteriouslycoredumping.2Chowtofixthis.3F
import pygtk
pygtk.require("2.0")
import gobject
gobject.threads_init()
import pygst
pygst.require("0.10")
import gst


from glue import segments
from glue import segmentsUtils
from glue.ligolw import utils
from glue.ligolw.utils import segments as ligolw_segments
from pylal.datatypes import LIGOTimeGPS
from gstlal import ligolw_output
from gstlal import svd_bank
from gstlal import pipeparts
from gstlal import lloidparts
from gstlal import reference_psd


def excepthook(*args):
	# system exception hook that forces hard exit.  without this,
	# exceptions that occur inside python code invoked as a call-back
	# from the gstreamer pipeline just stop the pipeline, they don't
	# cause gstreamer to exit.

	# FIXME:  they probably *would* cause if we could figure out why
	# element errors and the like simply stop the pipeline instead of
	# crashing it, as well.  Perhaps this should be removed when/if the
	# "element error's don't crash program" problem is fixed
	sys.__excepthook__(*args)
	os._exit(1)

sys.excepthook = excepthook


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#

def parse_banks(bank_string):
	"""
	parses strings of form H1:bank1.xml,H2:bank2.xml,L1:bank3.xml,H2:bank4.xml,...
	"""
	out = {}
	if bank_string is None:
		return out
	for b in bank_string.split(','):
		ifo, bank = b.split(':')
		out.setdefault(ifo, []).append(bank)
	return out

def parse_command_line():
	parser = OptionParser(
		description = __doc__
	)
	parser.add_option("--frame-cache", metavar = "filename", help = "Set the name of the LAL cache listing the LIGO-Virgo .gwf frame files (optional).  This is required unless --fake-data is used in which case it must not be set.")
	parser.add_option("--frame-segments-file", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load frame segments (optional).  If this is not provided then all data between --gps-start-time and --gps-end-time will be analyzed.  If this is provided then --frame-segments-name must also be set.")
	parser.add_option("--frame-segments-name", metavar = "name", help = "Set the name of the segments to extract from the segment tables in --frame-segments-file (optional, required if --frame-segments-file is given).")
	parser.add_option("--fake-data", metavar = "[LIGO|AdvLIGO]", help = "Instead of reading data from .gwf files, generate and process coloured Gaussian noise.")
	parser.add_option("--gps-start-time", metavar = "seconds", help = "Set the start time of the frame data to analyze in GPS seconds (required).  Can be specified to nanosecond precision.")
	parser.add_option("--gps-end-time", metavar = "seconds", help = "Set the end time of the frame data to analyze in GPS seconds (required).  Can be specified to nanosecond precision.")
	parser.add_option("--injections", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load injections (optional).")
	parser.add_option("--veto-segments-file", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load vetoes (optional).")
	parser.add_option("--veto-segments-name", metavar = "name", help = "Set the name of the segments to extract from the segment tables and use as the veto list.", default = "vetoes")
	parser.add_option("--channel-name", metavar = "name", default = "LSC-STRAIN", help = "Set the name of the channel to process (optional).  The default is \"LSC-STRAIN\".")
	parser.add_option("--nxydump-segment", metavar = "start:stop", default = ":", help = "Set the time interval to dump from nxydump elments (optional).  The default is \":\", i.e. dump all time.")
	parser.add_option("--output", metavar = "filename", help = "Set the name of the LIGO light-weight XML output file *.{xml,xml.gz} or an SQLite database *.sqlite (required).")
	parser.add_option("--reference-psd", metavar = "filename", help = "Instead of measuring the noise spectrum, load the spectrum from this LIGO light-weight XML file (optional).")
	parser.add_option("--track-psd", action = "store_true", help = "Track PSD even if a reference is given")
	parser.add_option("--svd-bank", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load the svd bank for a given instrument in the form ifo:file These can be given as a comma separated list such as H1:file1,H2:file2,L1:file3 to analyze multiple instruments.")
	parser.add_option("--time-slide-file", metavar = "filename", help = "Set the name of the xml file to get time slide offsets")
	parser.add_option("--control-peak-time", metavar = "time", type = "int", help = "Set a time window in seconds to find peaks in the control signal")
	parser.add_option("--fir-stride", metavar = "time", type = "int", default=8, help = "Set the length of the fir filter stride in seconds. default = 8")
	parser.add_option("--ht-gate-threshold", metavar = "threshold", type = "float", help = "Set the threshold on whitened h(t) to mark samples as gaps (glitch removal)")
	parser.add_option("--chisq-type", metavar = "type", default = "autochisq", help = "Choose the type of chisq computation to perform. Must be one of (autochisq|timeslicechisq). The default is autochisq.")
	parser.add_option("--coincidence-threshold", metavar = "value", type = "float", default = 0.020, help = "Set the coincidence window in seconds (default = 0.020).  The light-travel time between instruments will be added automatically in the coincidence test.")
	parser.add_option("--write-pipeline", metavar = "filename", help = "Write a DOT graph description of the as-built pipeline to this file (optional).  The environment variable GST_DEBUG_DUMP_DOT_DIR must be set for this option to work.")
	parser.add_option("--comment", help = "Set the string to be recorded in comment and tag columns in various places in the output file (optional).")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose (optional).")
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")

	options, filenames = parser.parse_args()

	if len([option for option in ("frame_cache", "fake_data") if getattr(options, option) is not None]) != 1:
		raise ValueError, "must provide exactly one of --frame-cache, --fake-data"

	if options.fake_data not in (None, "LIGO", "AdvLIGO"):
		raise ValueError("unrecognized value for --fake-data %s" % options.fake_data)

	if options.reference_psd is None and not options.track_psd:
		raise ValueError("must use --track-psd if no reference psd is given, you can use both simultaneously")

	required_options = ["output"]
	if options.frame_cache:
		required_options += ["channel_name", "gps_start_time", "gps_end_time"]
	if options.frame_segments_file:
		required_options += ["frame_segments_name"]
	if options.frame_segments_name:
		required_options += ["frame_segments_file"]

	missing_options = []
	if options.svd_bank is None:
		missing_options += ["--svd-bank"]
	missing_options += ["--%s" % option.replace("_", "-") for option in required_options if getattr(options, option) is None]
	if missing_options:
		raise ValueError, "missing required option(s) %s" % ", ".join(sorted(missing_options))

	# Get the banks and make the detectors
	# FIXME add error checking on length of banks per detector, etc
	svd_banks = parse_banks(options.svd_bank)
	# FIXME if the channel names are different for different detectors this won't work
	detectors = {}
	for instrument in set(svd_banks.keys()):
		detectors[instrument] = lloidparts.DetectorData(options.frame_cache, options.channel_name)

	# FIXME: should also check for read permissions
	required_files = []
	for instrument in svd_banks:
		required_files.extend(svd_banks[instrument])

	if options.frame_segments_file:
		required_files += [options.frame_segments_file]
	if options.veto_segments_file:
		required_files += [options.veto_segments_file]
	missing_files = [filename for filename in required_files if not os.path.exists(filename)]
	if missing_files:
		raise ValueError, "files %s do not exist" % ", ".join("'%s'" % filename for filename in sorted(missing_files))

	if options.chisq_type not in ["autochisq", "timeslicechisq"]:
		raise ValueError, "--chisq-type must be one of (autochisq|timeslicechisq), given %s" % (options.chisq_type)

	# do this before converting option types
	process_params = ligolw_output.make_process_params(options)

	options.seg = segments.segment(LIGOTimeGPS(options.gps_start_time), LIGOTimeGPS(options.gps_end_time))

	options.nxydump_segment, = segmentsUtils.from_range_strings([options.nxydump_segment], boundtype = LIGOTimeGPS)

	# hard-coded.  this number is needed in a few places, and storing
	# it in with the options is a convenient home
	options.psd_fft_length = 8	# seconds

	return options, filenames, process_params, svd_banks, detectors


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


#
# parse command line
#


options, filenames, process_params, svd_banks, detectors = parse_command_line()


#
# Parse the segments file(s) if provided
#


if options.frame_segments_file is not None:
	frame_segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.frame_segments_file, verbose = options.verbose), options.frame_segments_name).coalesce()
else:
	frame_segments = dict([(instrument, None) for instrument in detectors])

#
# Parse the vetos segments file(s) if provided
#


if options.veto_segments_file is not None:
	veto_segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.veto_segments_file, verbose = options.verbose), options.veto_segments_name).coalesce()
else:
	veto_segments = None


#
# Set up seek
#


seekevent = gst.event_new_seek(1., gst.FORMAT_TIME, gst.SEEK_FLAG_FLUSH | gst.SEEK_FLAG_KEY_UNIT, gst.SEEK_TYPE_SET, options.seg[0], gst.SEEK_TYPE_SET, options.seg[1])


#
# set up the PSDs
#
# There are three modes for psds in this program
# 1) --reference-psd without --track-psd - a fixed psd (provided by the user) will be used to whiten the data
# 2) --track-psd without --reference-psd - a psd will me measured and used on the fly
# 3) --track-psd with --reference-psd - a psd will be measured on the fly, but the first "guess will come from the users provided psd
#


if options.reference_psd is not None:
	psd = reference_psd.read_psd(options.reference_psd, verbose = options.verbose)
else:
	psd = dict([(instrument, None) for instrument in detectors])


#
# Parse template banks
#


banks = {}

for instrument, files in svd_banks.items():
	for n, filename in enumerate(files):
		# FIXME over ride the file name stored in the bank file with
		# this file name this bank I/O code needs to be fixed
		bank = svd_bank.read_bank(filename, verbose = options.verbose)
		bank.template_bank_filename = filename
		bank.logname = "%sbank%d" % (instrument,n)
		bank.number = n
		banks.setdefault(instrument,[]).append(bank)


#
# Build pipeline
#


if options.verbose:
	print >>sys.stderr, "assembling pipeline ...",

pipeline = gst.Pipeline("gstlal_inspiral")
mainloop = gobject.MainLoop()
handler = lloidparts.LLOIDHandler(mainloop, pipeline)


triggersrc = lloidparts.mkLLOIDmulti(
	pipeline,
	seekevent,
	detectors = detectors,
	banks = banks,
	psd = psd,
	psd_fft_length = options.psd_fft_length,
	fake_data = options.fake_data,
	injection_filename = options.injections,
	ht_gate_threshold = options.ht_gate_threshold,
	veto_segments = veto_segments,
	verbose = options.verbose,
	nxydump_segment = options.nxydump_segment,
	frame_segments = frame_segments,
	chisq_type = options.chisq_type,
	track_psd = options.track_psd,
	control_peak_time = options.control_peak_time,
	fir_stride = options.fir_stride
)


if options.verbose:
	print >>sys.stderr, "done"


#
# build output document
#


if options.verbose:
	print >>sys.stderr, "initializing output document ..."
output = ligolw_output.Data(
	filename = options.output,
	process_params = process_params,
	instruments = set(detectors),
	seg = options.seg,
	out_seg = options.seg, #FIXME make better outseg def?  Maybe pointless now that gstlal inspiral can analyze over frame gaps
	injection_filename = options.injections,
	time_slide_file = options.time_slide_file,
	comment = options.comment,
	tmp_path = options.tmp_space,
	verbose = options.verbose
)
stream_thinca = lloidparts.StreamThinca(
	output,
	coincidence_threshold = options.coincidence_threshold,
	coincidence_back_off = 50,	# coincidence back-off is big enough to handle buffer slop, max time slide offset automatically added.
	thinca_interval = 50.0	# seconds
)
if options.verbose:
	print >>sys.stderr, "... output document initialized"

if options.verbose:
	print >>sys.stderr, "attaching appsinks to pipeline ...",

appsinks = set()
appsync = pipeparts.AppSync(appsink_new_buffer = stream_thinca.appsink_new_buffer)

for src in triggersrc:
	sink = appsync.add_sink(pipeline, pipeparts.mkqueue(pipeline, src), caps = gst.Caps("application/x-lal-snglinspiral"))
	sink.connect_after("new-buffer", appsync.pull_appsinks_in_order)
	appsinks.add(sink)
if options.verbose:
	print >>sys.stderr, "attached %d, done" % len(appsinks)

if options.write_pipeline is not None:
	#
	# add a signal handler to write a pipeline graph upon receipt of
	# the first trigger buffer.  the caps in the pipeline graph are not
	# fully negotiated until data comes out the end, so this version of
	# the graph shows the final formats on all links
	#

	class AppsinkDumpDotData(object):
		lock = threading.Lock()
		n = 0
		write_after = len(appsinks)
		pipeline = pipeline
		filestem = "%s.%s" % (options.write_pipeline, "TRIGGERS")
		verbose = options.verbose

		def __init__(self):
			self.handler_id = None

		def execute(self):
			self.lock.acquire()
			self.n += 1
			if self.n >= self.write_after:
				pipeparts.write_dump_dot(self.pipeline, self.filestem, verbose = self.verbose)
			self.lock.release()

	def appsink_dump_dot(elem, appsink_dump_dot_data):
		appsink_dump_dot_data.execute()
		elem.disconnect(appsink_dump_dot_data.handler_id)

	for sink in appsinks:
		appsink_dump_dot_data = AppsinkDumpDotData()
		appsink_dump_dot_data.handler_id = sink.connect_after("new-buffer", appsink_dump_dot, appsink_dump_dot_data)


#
# process requested segment
#


if options.write_pipeline is not None:
	write_dump_dot(pipeline, "%s.%s" % (options.write_pipeline, "NULL"), verbose = options.verbose)

if options.verbose:
	print >>sys.stderr, "setting pipeline state to paused ..."
if pipeline.set_state(gst.STATE_PAUSED) != gst.STATE_CHANGE_SUCCESS:
	raise RuntimeError, "pipeline did not enter paused state"

if options.verbose:
	print >>sys.stderr, "setting pipeline state to playing ..."
if pipeline.set_state(gst.STATE_PLAYING) != gst.STATE_CHANGE_SUCCESS:
	raise RuntimeError, "pipeline did not enter playing state"

if options.write_pipeline is not None:
	write_dump_dot(pipeline, "%s.%s" % (options.write_pipeline, "PLAYING"), verbose = options.verbose)

if options.verbose:
	print >>sys.stderr, "running pipeline ..."
mainloop.run()


#
# write output file
#


stream_thinca.flush()
output.write_output_file(verbose = options.verbose)


#
# done
#
