#!/usr/bin/env python
#
# Copyright (C) 2011  Shaun Hooper, Chad Hanna
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
"""Stream-based inspiral analysis tool use IIR filters"""


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


import sys
import os
import threading
import warnings
from optparse import OptionParser


# The following snippet is taken from http://gstreamer.freedesktop.org/wiki/FAQ#Mypygstprogramismysteriouslycoredumping.2Chowtofixthis.3F
import pygtk
pygtk.require("2.0")
import gobject
gobject.threads_init()
import pygst
pygst.require("0.10")
import gst


from glue import segments
from glue import segmentsUtils
from glue.ligolw import utils
from glue.ligolw.utils import segments as ligolw_segments
from pylal.datatypes import LIGOTimeGPS
from gstlal import ligolw_output
from gstlal import pipeparts
from gstlal import lloidparts
from gstlal import reference_psd
from gstlal import cbc_template_iir
from gstlal import streamthinca


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#

def parse_banks(bank_string):
	"""
	parses strings of form H1:bank1.xml,H2:bank2.xml,L1:bank3.xml,H2:bank4.xml,...
	"""
	out = {}
	if bank_string is None:
		return out
	for b in bank_string.split(','):
		ifo, bank = b.split(':')
		out.setdefault(ifo, []).append(bank)
	return out

def parse_command_line():
	parser = OptionParser(description = __doc__)
	parser.add_option("--frame-cache", metavar = "filename", help = "Set the name of the LAL cache listing the LIGO-Virgo .gwf frame files (optional).  This is required unless --fake-data or --online-data is used in which case it must not be set.")
	parser.add_option("--frame-segments-file", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load frame segments (optional).  If this is not provided then all data between --gps-start-time and --gps-end-time will be analyzed.  If this is provided then --frame-segments-name must also be set.")
	parser.add_option("--frame-segments-name", metavar = "name", help = "Set the name of the segments to extract from the segment tables in --frame-segments-file (optional, required if --frame-segments-file is given).")
	parser.add_option("--fake-data", metavar = "[LIGO|AdvLIGO]", help = "Instead of reading data from .gwf files, generate and process coloured Gaussian noise.")
	parser.add_option("--gps-start-time", help="GPS start time (required)", type="float")
	parser.add_option("--gps-end-time", help="GPS end time (required)", type="float")
	parser.add_option("--injections", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load injections (optional).")
	parser.add_option("--veto-segments-file", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load vetoes (optional).")
	parser.add_option("--veto-segments-name", metavar = "name", help = "Set the name of the segments to extract from the segment tables and use as the veto list.", default = "vetoes")
	parser.add_option("--channel-name", metavar="channel", help="set the channel default LSC-STRAIN", default="LSC-STRAIN")
	parser.add_option("--flow", metavar = "Hz", type = "float", default = 40.0, help = "Set the template low-frequency cut-off (default = 40.0).")
	parser.add_option("--nxydump-segment", metavar = "start:stop", default = ":", help = "Set the time interval to dump from nxydump elments (optional).  The default is \":\", i.e. dump all time.")
	parser.add_option("--output", metavar = "filename", help = "Set the filename in which to save the triggers (required)")
	parser.add_option("--reference-psd", metavar = "filename", help = "load the spectrum from this LIGO light-weight XML file (required).")
	parser.add_option("--track-psd", action = "store_true", help = "Track PSD even if a reference is given")
	parser.add_option("--iir-bank", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load the iir template bank (required) format H1:bank1.xml,H2:bank2.xml,L1:bank3.xml,H2:bank4.xml,...")
	parser.add_option("--time-slide-file", metavar = "filename", help = "Set the name of the xml file to get time slide offsets")
	parser.add_option("--control-peak-time", metavar = "time", type = "int", help = "Set a time window in seconds to find peaks in the control signal")
	parser.add_option("--ht-gate-threshold", metavar = "threshold", type = "float", help = "Set the threshold on whitened h(t) to mark samples as gaps (glitch removal)")
	parser.add_option("--snr-threshold", type="float", help="SNR threshold default 5.5", default=5.5)
	parser.add_option("--chisq-type", metavar = "type", default = "autochisq", help = "Choose the type of chisq computation to perform. Must be one of (autochisq|timeslicechisq). The default is autochisq.")
	parser.add_option("--coincidence-threshold", metavar = "value", type = "float", default = 0.020, help = "Set the coincidence window in seconds (default = 0.020).  The light-travel time between instruments will be added automatically in the coincidence test.")
	parser.add_option("--write-pipeline", metavar = "filename", help = "Write a DOT graph description of the as-built pipeline to this file (optional).  The environment variable GST_DEBUG_DUMP_DOT_DIR must be set for this option to work.")
	parser.add_option("--comment",  metavar="str")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose (optional).")
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")

	options, filenames = parser.parse_args()

	if sum(1 for option in ('frame_cache', 'fake_data', ) if getattr(options, option) is not None) != 1: # FIXME: what about oline_data?
		raise ValueError, "must provide exactly one of --frame-cache, --fake-data"

	if options.fake_data not in (None, "LIGO", "AdvLIGO"):
		raise ValueError("unrecognized value for --fake-data %s" % options.fake_data)

	required_options = ["output"]
	if options.frame_cache:
		required_options += ["channel_name", "gps_start_time", "gps_end_time"]
	if options.frame_segments_file:
		required_options += ["frame_segments_name"]
	if options.frame_segments_name:
		required_options += ["frame_segments_file"]

	missing_options = []
	if options.iir_bank is None:
		missing_options += ["--iir-bank"]
	missing_options += ["--%s" % option.replace("_", "-") for option in required_options if getattr(options, option) is None]
	if missing_options:
		raise ValueError, "missing required option(s) %s" % ", ".join(sorted(missing_options))

	# Get the banks and make the detectors
	iir_banks = parse_banks(options.iir_bank)
	detectors = {}
	required_files = []
	for instrument in set(iir_banks.keys()):
		detectors[instrument] = lloidparts.DetectorData(options.frame_cache, options.channel_name)

	if options.frame_segments_file:
		required_files += [options.frame_segments_file]
	if options.veto_segments_file:
		required_files += [options.veto_segments_file]
	missing_files = [filename for filename in required_files if not os.path.exists(filename)]
	if missing_files:
		raise ValueError, "files %s do not exist" % ", ".join("'%s'" % filename for filename in sorted(missing_files))

	process_params = options.__dict__.copy() #FIXME override program name

	options.seg = segments.segment(LIGOTimeGPS(options.gps_start_time), LIGOTimeGPS(options.gps_end_time))

	options.nxydump_segment, = segmentsUtils.from_range_strings([options.nxydump_segment], boundtype = LIGOTimeGPS)

	# hard-coded.  this number is needed in a few places, and storing
	# it in with the options is a convenient home
	options.psd_fft_length = 8	# seconds

	return options, filenames, process_params, iir_banks, detectors

#
# =============================================================================
#
#                                     Misc
#
# =============================================================================
#


#
# write the pipeline to a dot file.
#


def write_dump_dot(pipeline, filestem, verbose = False):
	"""
	This function needs the environment variable GST_DEBUG_DUMP_DOT_DIR
	to be set.   The filename will be

	os.path.join($GST_DEBUG_DUMP_DOT_DIR, filestem + ".dot")

	If verbose is True, a message will be written to stderr.
	"""
	if "GST_DEBUG_DUMP_DOT_DIR" not in os.environ:
		raise ValueError, "cannot write pipeline, environment variable GST_DEBUG_DUMP_DOT_DIR is not set"
	gst.DEBUG_BIN_TO_DOT_FILE(pipeline, gst.DEBUG_GRAPH_SHOW_ALL, filestem)
	if verbose:
		print >>sys.stderr, "Wrote pipeline to %s" % os.path.join(os.environ["GST_DEBUG_DUMP_DOT_DIR"], "%s.dot" % filestem)


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


#
# parse command line
#


options, filenames, process_params, iir_banks, detectors = parse_command_line()


#
# Parse the segments file(s) if provided
#


if options.frame_segments_file is not None:
	frame_segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.frame_segments_file, verbose = options.verbose), options.frame_segments_name).coalesce()
else:
	frame_segments = {}
	for instrument in detectors:
		frame_segments[instrument] = None

if options.veto_segments_file is not None:
	veto_segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.veto_segments_file, verbose = options.verbose), options.veto_segments_name).coalesce()
else:
	veto_segments = None


#
# construct pipeline metadata and measure or retrieve the PSD
#


seekevent = lloidparts.seek_event_for_gps(options.gps_start_time, options.gps_end_time)


# FIXME correct where this is actually used, and for track psd
psd = {}
for instrument in detectors:
	if options.reference_psd is not None:
		psd[instrument] = reference_psd.read_psd(options.reference_psd, verbose = options.verbose)[instrument]
	else:
		psd[instrument] = None
## else:
## 	for instrument in detectors:
## 		# FIXME right now vetoes are applied after whitening.  If that
## 		# changes this function will need to know about vetoes too
## 		psd[instrument] = reference_psd.measure_psd(
## 			instrument,
## 			seekevent,
## 			detectors[instrument],
## 			options.seg,
## 			2 * 2048,	# Hz;  must not be less than highest bank fragment sample rate (see below)
## 			psd_fft_length = options.psd_fft_length,
## 			fake_data = options.fake_data,
## 			injection_filename = options.injections,
## 			verbose = options.verbose
## 		)
## 		if options.write_psd is not None:
## 			reference_psd.write_psd("%s-%s" % (instrument, options.write_psd), psd, instrument=instrument, verbose = options.verbose)


#
# Get IIR banks
#

banks = {}

for instrument, files in iir_banks.items():
	for filename in files:
		bank = cbc_template_iir.load_iirbank(filename, options.snr_threshold, options.verbose)
		banks.setdefault(instrument,[]).append(bank)

for instrument in banks:
	for n, bank in enumerate(banks[instrument]):
		bank.logname = "%sbank%d" % (instrument,n)

#
# Build pipeline
#


if options.verbose:
	print >>sys.stderr, "assembling pipeline ...",

pipeline = gst.Pipeline("gstlal_iir_inspiral")
mainloop = gobject.MainLoop()
handler = lloidparts.LLOIDHandler(mainloop, pipeline)


triggersrc = lloidparts.mkSPIIRmulti(
	pipeline,
	seekevent,
	detectors = detectors,
	banks = banks,
	psd = psd,
	psd_fft_length = options.psd_fft_length,
	fake_data = options.fake_data,
	online_data = None, # FIXME so that this can use options.online_data,
	injection_filename = options.injections,
	ht_gate_threshold = options.ht_gate_threshold,
	veto_segments = veto_segments,
	verbose = options.verbose,
	nxydump_segment = options.nxydump_segment,
	frame_segments = frame_segments,
	chisq_type = options.chisq_type,
	track_psd = options.track_psd,
)


if options.verbose:
	print >>sys.stderr, "done"


#
# build output document
#


if options.verbose:
	print >>sys.stderr, "initializing output document ..."
output = ligolw_output.Data(
	filename = options.output,
	process_params = process_params,
	instruments = set(detectors),
	seg = options.seg,
	out_seg = options.seg, #FIXME make better outseg def?  Maybe pointless now that gstlal inspiral can analyze over frame gaps
	injection_filename = options.injections,
	time_slide_file = options.time_slide_file,
	comment = options.comment,
	tmp_path = options.tmp_space,
	verbose = options.verbose
)
#FIXME dont hardcode some of this
stream_thinca = streamthinca.StreamThinca(
  	output,
	coincidence_threshold = options.coincidence_threshold,
	coincidence_back_off = 50,	# coincidence back-off is big enough to handle buffer slop, max time slide offset automatically added. 
	thinca_interval = 50.0	# seconds
)
if options.verbose:
	print >>sys.stderr, "... output document initialized"

if options.verbose:
	print >>sys.stderr, "attaching appsinks to pipeline ...",
appsync = pipeparts.AppSync(appsink_new_buffer = stream_thinca.appsink_new_buffer)
appsinks = set(appsync.add_sink(pipeline, pipeparts.mkqueue(pipeline, src), caps = gst.Caps("application/x-lal-snglinspiral")) for src in triggersrc)
if options.verbose:
	print >>sys.stderr, "attached %d, done" % len(appsinks)

if options.write_pipeline is not None:
	#
	# add a signal handler to write a pipeline graph upon receipt of
	# the first trigger buffer.  the caps in the pipeline graph are not
	# fully negotiated until data comes out the end, so this version of
	# the graph shows the final formats on all links
	#

	class AppsinkDumpDotData(object):
		lock = threading.Lock()
		n = 0
		write_after = len(appsinks)
		pipeline = pipeline
		filestem = "%s.%s" % (options.write_pipeline, "TRIGGERS")
		verbose = options.verbose

		def __init__(self):
			self.handler_id = None

		def execute(self):
			self.lock.acquire()
			self.n += 1
			if self.n >= self.write_after:
				write_dump_dot(self.pipeline, self.filestem, verbose = self.verbose)
			self.lock.release()

	def appsink_dump_dot(elem, appsink_dump_dot_data):
		appsink_dump_dot_data.execute()
		elem.disconnect(appsink_dump_dot_data.handler_id)

	for sink in appsinks:
		appsink_dump_dot_data = AppsinkDumpDotData()
		appsink_dump_dot_data.handler_id = sink.connect_after("new-buffer", appsink_dump_dot, appsink_dump_dot_data)

#
# process requested segment
#


if options.write_pipeline is not None:
	write_dump_dot(pipeline, "%s.%s" % (options.write_pipeline, "NULL"), verbose = options.verbose)

if options.verbose:
	print >>sys.stderr, "setting pipeline state to paused ..."
if pipeline.set_state(gst.STATE_PAUSED) != gst.STATE_CHANGE_SUCCESS:
	raise RuntimeError, "pipeline did not enter paused state"

if options.verbose:
	print >>sys.stderr, "setting pipeline state to playing ..."
if pipeline.set_state(gst.STATE_PLAYING) != gst.STATE_CHANGE_SUCCESS:
	raise RuntimeError, "pipeline did not enter playing state"

if options.write_pipeline is not None:
	write_dump_dot(pipeline, "%s.%s" % (options.write_pipeline, "PLAYING"), verbose = options.verbose)

if options.verbose:
	print >>sys.stderr, "running pipeline ..."
mainloop.run()


#
# write output file
#


stream_thinca.flush()
output.write_output_file(verbose = options.verbose)


#
# done
#
