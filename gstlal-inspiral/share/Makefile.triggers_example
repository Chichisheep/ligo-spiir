## @file
# An example configuration file to create a gstlal_inspiral workflow
# Tailored to BNS but can be adapted to other sources by chaning parameters or programs

## Template bank parameters
# Note that these can can change if you modify the template bank program.
MIN_MASS = 1.0				# Minimum component mass for the template bank
MAX_MASS = 3.0				# Maximum component mass for the template bank
MIN_TOTAL_MASS = 2.0			# Minimum total mass for the template bank
MAX_TOTAL_MASS = 6.0			# Maximum total mass for the template bank
LOW_FREQUENCY_CUTOFF = 40.0		# Low frequency cut off for the template bank placement
HIGH_PASS_FREQ = 35			# High pass frequency to condition the data before measuring the psd for template placement
HIGH_FREQUENCY_CUTOFF = 2047.0		# Highest frequency at which to compute the metric
SAMPLE_RATE = 4096			# The sample rate at which to compute the template bank
MM = 0.975				# The minimal match of the template bank; determines how much SNR is retained for signals "in between the bank points"
BANKSTART = 966393725			# The start time for reading the data for the bank
BANKSTOP =  966395773			# The stop time for reading the data for the bank


## Sub bank parameters
# The large template bank is split into sub banks before they are SVD'd
NUM_SPLIT_TEMPLATES = 100		# Number of templates to put in each sub bank; this should probably always be ~100. For highly degenerate banks it might be possible to make this 200 or so.  
OVERLAP = 10 				# The number of templates to overlap for each sub bank. This overlap just goes into the SVD, the overlapping templates are not reconstructed and the bank remains contiguous

## Controls trigger creation
#
IFOS = H1 L1 V1				# The dectors to analyze; provide as a space separated list
START = 966384015			# The start time to analyze
STOP = 967384015			# The end time to analyze
TAG = Test				# The tag to name the output web directory
WEBDIR = ~/public_html/${START}-${STOP}-${TAG}	# the output directory for the results
NUMBANKS = 4				# The number of sub banks to analyze in parallel.  This means that the total number of templates in parallel is NUMBANKS * NUM_SPLIT_TEMPLATES * num(IFOS);  A typical number of parallel templates might be 4 * 100 * 3 = 1200.  Setting this too high might cause memory to be exhausted
PEAK = 0				# If non-zero, this is the interval over which to apply the composite detection statistic to avoid reconstructing all of the SVD filters
AC_LENGTH = 351				# The length in samples of the auto correlation "chisquared" veto.
# additional options, e.g.,
#ADDITIONAL_DAG_OPTIONS = "--blind-injections BNS-MDC1-WIDE.xml"

## Injections
# The seed is the string before the suffix _injections.xml
# Change as appropriate, whitespace is important
# NOTE This uses gstlal_injections_by_local_rate for this example, but you might want to use lalapps_inspinj since it is reviewed etc.
INJECTIONS := 1_injections.xml 2_injections.xml	# specify the seeds and number of injections.  The should be <seed>_injections.xml.  The same rule will be applied to each target.  For a more heterogeneous injection plan more work has to go into this Makefile but it is straight forward.
INJ_MAX_DIST = 150			# Maximum injection distance in Mpc
INJ_MIN_MASS1 = 1.0			# Minimum component mass 1 for injections
INJ_MAX_MASS1 = 3.0			# Maximum component msss 1 for injections
INJ_MIN_MASS2 = 1.0			# Minimum component mass 2 for injections
INJ_MAX_MASS2 = 3.0			# Maximum component mass 2 for injections
INJ_MIN_TOTAL_MASS = 2.0		# Minimum total mass for injections
INJ_MAX_TOTAL_MASS = 6.0		# Maximum total mass for injections
INJ_FLOW = 35				# minimum frequency for injections. NOTE this should be lower than the intended filtering frequency

## Segment and frame type info
SEG_SERVER=https://segdb.ligo.caltech.edu
LIGO_FRAME_TYPE='$*_T1200307_V4_EARLY_GAUSSIAN'
LIGO_SEGMENTS="$*:CBC-MDC1_SCIENCE_EARLY_GAUSSIAN"
VIRGO_FRAME_TYPE='V1_T1300121_V1_EARLY_GAUSSIAN'
CHANNEL_NAMES:=--channel-name=H1=GAUSSIAN --channel-name=L1=GAUSSIAN --channel-name=V1=GAUSSIAN # Channel names to analyze. NOTE every IFO should get a channel name, but they can be different and depend on the data

## FIXME MISSING vetoes
# In principle a similar set of segment queries can be written to extract vetoes
# That is not done in this example
# If you do decide to do it hten you have to pass the vetoes xml file to the DAG generator

## Get some basic definitions. YOU HAVE TO INCLUDE THIS BEFORE THE ACTUAL RULES OR THEY WONT WORK
include Makefile.offline_analysis_rules

#
# Workflow
#


all : dag

## Making the master template bank
H1-TMPLTBANK-966393725-2048.xml: H1_frame.cache
	lalapps_tmpltbank \
		--disable-compute-moments \
		--grid-spacing Hexagonal \
		--dynamic-range-exponent 69.0 \
		--enable-high-pass $(HIGH_PASS_FREQ) \
		--high-pass-order 8 \
		--strain-high-pass-order 8 \
		--minimum-mass $(MIN_MASS) \
		--maximum-mass $(MAX_MASS) \
		--min-total-mass $(MIN_TOTAL_MASS) \
		--max-total-mass $(MAX_TOTAL_MASS) \
		--gps-start-time $(BANKSTART) \
		--gps-end-time $(BANKSTOP) \
		--calibrated-data real_8 \
		--channel-name H1:GAUSSIAN \
		--space Tau0Tau3 \
		--number-of-segments 15 \
		--minimal-match $(MM) \
		--high-pass-attenuation 0.1 \
		--min-high-freq-cutoff ERD \
		--segment-length 1048576 \
		--low-frequency-cutoff $(LOW_FREQUENCY_CUTOFF) \
		--pad-data 8 \
		--num-freq-cutoffs 1 \
		--sample-rate $(SAMPLE_RATE) \
		--high-frequency-cutoff $(HIGH_FREQUENCY_CUTOFF) \
		--resample-filter ldas \
		--strain-high-pass-atten 0.1 \
		--strain-high-pass-freq $(HIGH_PASS_FREQ) \
		--frame-cache H1_frame.cache \
		--max-high-freq-cutoff ERD \
		--approximant TaylorF2 \
		--order twoPN \
		--spectrum-type median \
		--verbose 

## The program to to split the master template bank into sub banks
%_split_bank.cache : H1-TMPLTBANK-966393725-2048.xml
	mkdir -p $*_split_bank
	gstlal_bank_splitter --output-path $*_split_bank --output-cache $@ --overlap $(OVERLAP) --instrument $* --n $(NUM_SPLIT_TEMPLATES) --sort-by mchirp --add-f-final --max-f-final $(HIGH_FREQUENCY_CUTOFF) $<

## The directory where plots will go
plots :
	mkdir plots

## The output directory
$(WEBDIR) : 
	mkdir $(WEBDIR)

## Even though we don't use time slides for background estimation, we still need a time slide table. It is constructed of a zero lag vector and a single offset that we use for "closed box" results
tisi.xml :
	ligolw_tisi --instrument=H1=0:0:0 --instrument=H2=0:0:0 --instrument=L1=0:0:0 --instrument=V1=0:0:0 tisi0.xml
	ligolw_tisi --instrument=H1=0:0:0 --instrument=H2=0:0:0 --instrument=L1=3.14159:3.14159:3.14159 --instrument=V1=7.892:7.892:7.892 tisi1.xml
	ligolw_add --output $@ tisi0.xml tisi1.xml

## The dag generator and the whole point of this makefile. The result is a file: trigger_pipe.dag that can be submitted to HTCondor
dag : segments.xml frame.cache tisi.xml plots $(WEBDIR) $(INJECTIONS) $(BANK_CACHE_FILES)
	gstlal_inspiral_pipe --data-source frames --gps-start-time $(START) --gps-end-time $(STOP) --frame-cache frame.cache --frame-segments-file segments.xml --frame-segments-name datasegments  --control-peak-time $(PEAK) --num-banks $(NUMBANKS) --fir-stride 4 --web-dir $(WEBDIR) --time-slide-file tisi.xml $(INJECTION_LIST) --bank-cache $(BANK_CACHE_STRING) --tolerance 0.9999 --overlap $(OVERLAP) --flow $(LOW_FREQUENCY_CUTOFF) $(CHANNEL_NAMES) --autocorrelation-length $(AC_LENGTH) $(ADDITIONAL_DAG_OPTIONS)

## Excecute a single segment query for a given IFO
# Note: Virgo might sometimes need a special rule
%_segmentspadded.xml:
	ligolw_segment_query --segment-url=${SEG_SERVER} -q --gps-start-time ${START} --gps-end-time ${STOP} --include-segments=$(LIGO_SEGMENTS) --result-name=datasegments > $@

## Virgo datafind often requires a separate rule since the frame files have different types
V1_frame.cache:
	ligo_data_find -o V -t $(VIRGO_FRAME_TYPE) -l  -s $(START) -e $(STOP) --url-type file > $@

## Excute a datafind query for a given IFO
%_frame.cache:
	#FIXME horrible hack to get the observatory, not guaranteed to work
	$(eval OBS:=$*)
	$(eval OBS:=$(subst 1,$(empty),$(OBS)))
	$(eval OBS:=$(subst 2,$(empty),$(OBS)))
	ligo_data_find -o $(OBS) -t $(LIGO_FRAME_TYPE) -l  -s $(START) -e $(STOP) --url-type file > $@


## Combine the results of all the single IFO datafind queries into a single file
frame.cache: $(FRAME_CACHE_FILES)
	cat $(FRAME_CACHE_FILES) > frame.cache

## Combine the results of the segment database queries for all ifos into a single file
segments.xml: $(SEGMENTS_FILES) frame.cache
	ligolw_add --output segdb.xml $(SEGMENTS_FILES)
	ligolw_cut --delete-column segment:segment_def_cdb --delete-column segment:creator_db --delete-column segment_definer:insertion_time segdb.xml
	gstlal_cache_to_segments frame.cache nogaps.xml
	gstlal_segments_operations --segment-file1 segdb.xml --segment-file2 nogaps.xml --intersection --output-file $@
	-rm -vf nogaps.xml segdb.xml
	gstlal_segments_trim --trim 8 --min-length 512 --output $@ $@

## FIXME
# A similar procedure to the above semgent generation could/should be used to make veto files

## Generate injections, e.g., 1_injections.xml or 2_injections.xml for whatever seeds are requested
%_injections.xml: 
	gstlal_injections_by_local_rate \
		--output $@ \
		--seed $* \
		--flower $(INJ_FLOW) \
		--gps-start-time $(START) \
		--gps-end-time $(STOP) \
		--bns-max-distance $(INJ_MAX_DIST) \
		--nsbh-local-rate 0 \
		--bbh-local-rate 0 \
		--bns-local-rate 22000

## Cleanup by deleting all of files created.  WARNING this will completly obliterate an analysis. 
clean :
	-rm -rvf *.sub *.dag* *.cache *.sh logs *.sqlite plots $(WEBDIR) *.html Images *.css *.js
	-rm -rvf lalapps_run_sqlite/ ligolw_* gstlal_*
	-rm -vf segments.xml tisi.xml H*.xml L*.xml V*.xml ?_injections.xml ????-*_split_bank-*.xml
	-rm -vf *marginalized*.xml.gz *-ALL_LLOID*.xml.gz
	-rm -vf tisi0.xml tisi1.xml
