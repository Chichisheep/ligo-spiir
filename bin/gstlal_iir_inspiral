#!/usr/bin/env python
#
# Copyright (C) 2011  Shaun Hooper, Chad Hanna
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
"""Stream-based inspiral analysis tool use IIR filters"""


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


import sys
import os
import scipy
import numpy
#import pylab
from optparse import OptionParser
from glue import segments
from glue import segmentsUtils
from pylal.datatypes import LIGOTimeGPS
from pylal.xlal.datatypes.snglinspiraltable import from_buffer as sngl_inspirals_from_buffer
from gstlal import ligolw_output


def parse_banks(bank_string):
	"""
	parses strings of form H1:bank1.xml,H2:bank2.xml,L1:bank3.xml,H2:bank4.xml,...
	"""
	out = {}
	if bank_string is None:
		return out
	for b in bank_string.split(','):
		ifo, bank = b.split(':')
		out.setdefault(ifo, []).append(bank)
	return out


def iir_bank(pipeline, src, sample_rates, a1, b0, delay):
	#FIXME don't upsample everything to a common rate
	max_rate = max(sample_rates)
	adder = gst.element_factory_make("lal_adder")
	adder.set_property("sync", True)
	pipeline.add(adder)

	for sr in sample_rates:
		#print D[sr].min()
		#head = pipeparts.mkdrop(pipeline, src[sr], drop_samples=D[sr].min())
		head = pipeparts.mkqueue(pipeline, src[sr], max_size_time=gst.SECOND * 10, max_size_buffers=0, max_size_bytes=0)
		#head = pipeparts.mkiirbank(pipeline, head, a1 = a1[sr], b0 = b0[sr], delay = delay[sr], name = "gstlaliirbank%d" % (sr)) # FIXME: does the name need to be unique?
		head = pipeparts.mkprogressreport(pipeline, head, "afteriirbank_%d" % (sr))
		head = pipeparts.mkresample(pipeline, head)
		# FIXME make this queue the "right" size
		head = pipeparts.mkqueue(pipeline, pipeparts.mkcapsfilter(pipeline, head, "audio/x-raw-float, rate=%d" % max_rate), max_size_time=gst.SECOND * 100, max_size_buffers=0, max_size_bytes=0)
		#head = pipeparts.mknxydumpsinktee(pipeline, head, "output_%d.txt" % (sr), segment = options.nxydump_segment)
		#head = pipeparts.mkqueue(pipeline, head)
		head.link(adder)

	adder = pipeparts.mkcapsfilter(pipeline, adder, "audio/x-raw-float, rate=%d" % max_rate)
	return adder


#
# A function for parsing command line
#

def parse_command_line():
	parser = OptionParser(description = __doc__)
	parser.add_option("--frame-cache", metavar = "filename", help = "Set the name of the LAL cache listing the LIGO-Virgo .gwf frame files (optional).  This is required unless --fake-data or --online-data is used in which case it must not be set.")
	parser.add_option("--fake-data", metavar = "[LIGO|AdvLIGO]", help = "Instead of reading data from .gwf files, generate and process coloured Gaussian noise.")
	parser.add_option("--iir-bank", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load the iir template bank (required) format H1:bank1.xml,H2:bank2.xml,L1:bank3.xml,H2:bank4.xml,...")
	#parser.add_option("--iir-bank2", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load the iir template bank (required) format H1:bank1.xml,H2:bank2.xml,L1:bank3.xml,H2:bank4.xml,...")
	parser.add_option("--injections", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load the injections (optional).")
	parser.add_option("--nxydump-segment", metavar = "start:stop", default = ":", help = "Set the time interval to dump from nxydump elments (optional).  The default is \":\", i.e. dump all time.")
	parser.add_option("--gps-start-time", help="GPS start time (required)", type="float")
	parser.add_option("--gps-end-time", help="GPS end time (required)", type="float")
	parser.add_option("--output", metavar = "filename", help = "Set the filename in which to save the triggers (required)")
	parser.add_option("--channel-name", metavar="channel", help="set the channel default LSC-STRAIN", default="LSC-STRAIN")
	parser.add_option("--tmp-space",  metavar="PATH")
	parser.add_option("--comment",  metavar="str")
	parser.add_option("--snr-threshold", type="float", help="SNR threshold default 5.5", default=5.5)
	parser.add_option("--reference-psd", metavar = "filename", help = "load the spectrum from this LIGO light-weight XML file (required).")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose (optional).")
	parser.add_option("--write-pipeline", metavar = "filename", help = "Write a DOT graph description of the as-built pipeline to this file (optional).  The environment variable GST_DEBUG_DUMP_DOT_DIR must be set for this option to work.")

	options, filenames = parser.parse_args()

	if sum(1 for option in ('frame_cache', 'fake_data', ) if getattr(options, option) is not None) != 1: # FIXME: what about oline_data?
		raise ValueError, "must provide exactly one of --frame-cache, --fake-data"

	if options.frame_cache:
		required_options += ["channel_name", "gps_start_time", "gps_end_time"]

	fail = ""
	for option in ("iir_bank", "output", "gps_start_time", "gps_end_time"):
		if getattr(options, option) is None:
			fail += "must provide option %s\n" % (option)

	if fail: raise ValueError, fail

	effective_gps_start_time = LIGOTimeGPS(options.gps_start_time)
	effective_gps_end_time = LIGOTimeGPS(options.gps_end_time)

	process_params = ligolw_output.make_process_params(options) #FIXME override program name
	options.seg = segments.segment(effective_gps_start_time, effective_gps_end_time)

	options.nxydump_segment, = segmentsUtils.from_range_strings([options.nxydump_segment], boundtype = LIGOTimeGPS)

	return options, filenames, process_params

#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#

#
# write the pipeline to a dot file.
#


def write_dump_dot(pipeline, filestem, verbose = False):
	"""
	This function needs the environment variable GST_DEBUG_DUMP_DOT_DIR
	to be set.   The filename will be

	os.path.join($GST_DEBUG_DUMP_DOT_DIR, filestem + ".dot")

	If verbose is True, a message will be written to stderr.
	"""
	if "GST_DEBUG_DUMP_DOT_DIR" not in os.environ:
		raise ValueError, "cannot write pipeline, environment variable GST_DEBUG_DUMP_DOT_DIR is not set"
	gst.DEBUG_BIN_TO_DOT_FILE(pipeline, gst.DEBUG_GRAPH_SHOW_ALL, filestem)
	if verbose:
		print >>sys.stderr, "Wrote pipeline to %s" % os.path.join(os.environ["GST_DEBUG_DUMP_DOT_DIR"], "%s.dot" % filestem)

#
# parse command line
#


options, filenames, process_params = parse_command_line()


#
# Import everything that depends on GStreamer
#

from gstlal import cbc_template_iir
from gstlal.pipeio import repack_complex_array_to_real, repack_real_array_to_complex
from gstlal.reference_psd import read_psd
from glue.ligolw import utils, param
from gstlal import pipeutil
from gstlal.lloidparts import seek_event_for_gps
from gstlal.pipeutil import gobject, gst
from gstlal import pipeparts
from gstlal import lloidparts


#
# extract parameters from the bank
#

banks = parse_banks(options.iir_bank)
#iirbanknds = parse_banks(options.iir_bank2)
snr_threshold = options.snr_threshold

# get the pipeline running
pipeline = gst.Pipeline("gstlal_iir_inspiral")
mainloop = gobject.MainLoop()
handler = lloidparts.LLOIDHandler(mainloop, pipeline)
seekevent = seek_event_for_gps(options.gps_start_time, options.gps_end_time)
options.out_seg = segments.segment(options.seg[0], options.seg[1]) #FIXME make better outseg def.


#
# loop over instruments FIXME for now it is just one instrument :)
#
detectors = {}
for ifo, bank in banks.items():
	detectors[ifo] = lloidparts.DetectorData(options.frame_cache, options.channel_name)

# FIXME ADD MORE
data = ligolw_output.Data(options.output, process_params, set(detectors), options.seg, options.out_seg, options.injections)

#FIXME dont hardcode some of this
stream_thinca = lloidparts.StreamThinca(
	data,
	coincidence_threshold = 0.015,
	coincidence_back_off = 2 * 5,	# coincidence back-off is twice AppSync dt
	thinca_interval = 50.0	# seconds
)

appsinks = set()
triggersrc = set()
appsync = pipeparts.AppSync(appsink_new_buffer = stream_thinca.appsink_new_buffer, dt = 5)

for ifo, bank in banks.items():

	bankfile = bank[0]

	#FIXME don't assume that you only want the 0th bank
	xmldoc = utils.load_filename(bankfile)
	#xmldocnds = utils.load_filename(options.iir_bank2)
	A, B, D, autocor = cbc_template_iir.get_matrices_from_xml(xmldoc)
	#Ands, Bnds, Dnds, autocornds = cbc_template_iir.get_matrices_from_xml(xmldocnds)

	sample_rates = [int(s) for s in param.get_pyvalue(xmldoc, 'sample_rate').split(',')]
	print sample_rates

	head = lloidparts.mkLLOIDbasicsrc(
		pipeline,
		seekevent,
		ifo,
		detector = detectors[ifo],
		fake_data = options.fake_data,
		injection_filename = options.injections,
		verbose = options.verbose)

	head = lloidparts.mkLLOIDsrc(pipeline, head, sample_rates, ifo, psd=None, psd_fft_length = 8, block_duration=gst.SECOND)
	head[max(sample_rates)] = pipeparts.mkprogressreport(pipeline, head[max(sample_rates)], "input")

	# Write input
	#head[max(sample_rates)] = pipeparts.mknxydumpsinktee(pipeline, head[max(sample_rates)], "input.txt", segment = options.nxydump_segment)



	# filter using FIR bank
	# read psd file
	#if options.reference_psd:
	#	psd = read_psd(options.reference_psd)[ifo]
	#	# smooth and create an interp object
	#	psd = cbc_template_iir.smooth_and_interp(psd)
	#else:
	#	psd = None

	#F, autocor = cbc_template_iir.get_fir_matrix(xmldoc, psd_interp=psd, verbose=options.verbose)
 	#firhead = head[max(sample_rates)] = pipeparts.mktee(pipeline, head[max(sample_rates)])
 	#firhead = pipeparts.mkqueue(pipeline, firhead, max_size_time = 2048 * gst.SECOND, max_size_bytes=0, max_size_buffers=0)
 	#firhead = pipeparts.mkfirbank(pipeline, firhead, fir_matrix = F, time_domain = False, block_stride = max(sample_rates) * 1024)
 	#firhead = pipeparts.mkqueue(pipeline, firhead)
 	#firhead = pipeparts.mkprogressreport(pipeline, firhead, "FIR output")
 	#firhead = pipeparts.mkqueue(pipeline, firhead)
 	#pipeparts.mknxydumpsink(pipeline, firhead, "output_fir_%s.txt" % (source), segment = options.nxydump_segment)


	# filter using high rate IIR bank
	#iirndshead = pipeparts.mkiirbank(pipeline, pipeparts.mkqueue(pipeline, iirndshead, max_size_time=gst.SECOND * 10, max_size_buffers=0, max_size_bytes=0), a1 = Ands[max(sample_rates)], b0 = Bnds[max(sample_rates)], delay = Dnds[max(sample_rates)])
	#pipeparts.mkfakesink(pipeline, iirndshead)
	#iirndshead = pipeparts.mkqueue(pipeline, iirndshead)
	#iirndshead = pipeparts.mkprogressreport(pipeline, iirndshead, "non-downsampled output")
	#iirndshead = pipeparts.mkqueue(pipeline, iirndshead)
	#pipeparts.mknxydumpsink(pipeline, iirndshead, "output_iir_%s_nds.txt" % (source), segment = options.nxydump_segment)


	# filter using IIR bank
	head = iir_bank(pipeline, head, sample_rates, a1 = A, b0 = B, delay = D) #FIXME should this be a1 = repack_complex_array_to_real(A)?
	head = pipeparts.mkqueue(pipeline, head)
	head = pipeparts.mknxydumpsinktee(pipeline, head, "output_iir.txt", segment = options.nxydump_segment)
	pipeparts.mkfakesink(pipeline, head)
	continue

	head = pipeparts.mktogglecomplex(pipeline, head)
	head = pipeparts.mknofakedisconts(pipeline, head)
	head = pipeparts.mkprogressreport(pipeline, head, "IIR output")
	# tee off and write output file
	head = pipeparts.mktogglecomplex(pipeline, head)

	for sr in sample_rates:
		pipeparts.mkfakesink(pipeline, head[sr])
	continue

	snr = chisq = pipeparts.mktee(pipeline, head)
	chisq = pipeparts.mkqueue(pipeline, chisq)
	chisq = pipeparts.mkautochisq(pipeline, chisq, autocorrelation_matrix = autocor, latency = -50, snr_thresh = snr_threshold)

	sigmasq=numpy.ones(len(autocor)) # FIXME: make sigmasq correct
	snr = pipeparts.mkqueue(pipeline, snr)

	triggergen = gst.element_factory_make("lal_triggergen")
	triggergen.set_property("bank-filename", bankfile)
	triggergen.set_property("snr-thresh", snr_threshold)
	triggergen.set_property("sigmasq", sigmasq)
	triggergen.set_property("max-gap", 1.0)
	pipeline.add(triggergen)
	snr.link_pads("src", triggergen, "snr")
	chisq.link(triggergen)
	triggersrc.add(triggergen)

# hook up the triggers
for trig in triggersrc:
	sink = appsync.add_sink(pipeline, pipeparts.mkqueue(pipeline, trig), caps = gst.Caps("application/x-lal-snglinspiral"))
	sink.connect_after("new-buffer", appsync.pull_appsinks_in_order)
	appsinks.add(sink)


############################################################
# run the pipeline

#gst.DEBUG_BIN_TO_DOT_FILE(pipeline, gst.DEBUG_GRAPH_SHOW_NON_DEFAULT_PARAMS, "gstlal_iir_inspiral_graph")
#pipeline.set_state(gst.STATE_PLAYING)


#
# process requested segment
#


if options.write_pipeline is not None:
	write_dump_dot(pipeline, "%s.%s" % (options.write_pipeline, "NULL"), verbose = options.verbose)

if options.verbose:
	print >>sys.stderr, "setting pipeline state to paused ..."
if pipeline.set_state(gst.STATE_PAUSED) != gst.STATE_CHANGE_SUCCESS:
	raise RuntimeError, "pipeline did not enter paused state"

if options.verbose:
	print >>sys.stderr, "setting pipeline state to playing ..."
if pipeline.set_state(gst.STATE_PLAYING) != gst.STATE_CHANGE_SUCCESS:
	raise RuntimeError, "pipeline did not enter playing state"

if options.write_pipeline is not None:
	write_dump_dot(pipeline, "%s.%s" % (options.write_pipeline, "PLAYING"), verbose = options.verbose)

if options.verbose:
	print >>sys.stderr, "running pipeline ..."
mainloop.run()

data.write_output_file()
