#!/usr/bin/python

# FIXME proper copyright and GPL notice
# Copyright 2011 Kipp Cannon, Chad Hanna

import sys
import numpy
from scipy import interpolate
from scipy.stats import poisson
from glue.ligolw import lsctables
from glue.ligolw import utils
from glue.ligolw.utils import process as ligolw_process
from glue.ligolw.utils import segments as ligolw_segments
from pylal import inject
from pylal import rate
from optparse import OptionParser
from gstlal import ligolw_output as gstlal_likelihood
from gstlal.svd_bank import read_bank
try:
	import sqlite3
except ImportError:
	# pre 2.5.x
	from pysqlite2 import dbapi2 as sqlite3

sqlite3.enable_callback_tracebacks(True)

def smooth_bins(bA):
	#FIXME what is this window supposed to be??
	wn = rate.gaussian_window2d(3, 3, sigma = 8)
	rate.filter_array(bA.array.T, wn)
	bA.array /= bA.array.sum()

def decimate_array(arr, size):
	if size > len(arr):
		size = len(arr)
	arr.sort()
	X = numpy.arange(1, len(arr)+1)
	Xnew = numpy.linspace(1, len(arr), size)
	interp = interpolate.interp1d(X, arr)
	out = interp(Xnew)
	return out

def linearize_array(arr):
	return arr.reshape((1,arr.shape[0] * arr.shape[1]))

def get_nonzero(arr):
	return arr[arr != 0]

class FAR(object):
	def __init__(self, livetime, trials_factor, counts = None):
		self.counts = counts
		self.livetime = livetime
		self.trials_factor = trials_factor

	def updateFAPmap(self, instruments):
		if self.counts is None:
			raise InputError, "must provide background bins file"
		
		nonzero = {}

		#
		# the target FAP resolution is 1 part in 10^7.  So depending on
		# how many instruments we have we have to take the nth root of
		# that number to set the scale in each detector. This is purely
		# for memory/CPU requirements
		#

		targetlen = int(1e7**(1. / len(instruments)))
		
		for ifo in instruments:
			nonzero[ifo] = decimate_array(get_nonzero(linearize_array(counts[ifo+"_snr_chi"].array)), targetlen)
		self.ranks = self.possible_ranks_array(nonzero.values())

		# compute the false alarm probability (FAP) from possible ranks
		FAP = (numpy.arange(len(self.ranks)) + 1.) / len(self.ranks)
		self.fap_from_rank = interpolate.interp1d(self.ranks, FAP, fill_value = 0., bounds_error = False)
		

	def possible_ranks_array(self, arrays):
		out = arrays[0]
		for array in arrays[1:]:
			out = numpy.outer(out, array)
			out = out.reshape((out.shape[0] * out.shape[1],))
		out.sort()
		return out

	# Method only works if counts is not None:
	def compute_rank(self, snr_chisq_dict):
		if self.counts is None:
			raise InputError, "must provide background bins file"
		rank = 1
		for ifo, (snr,chisq) in snr_chisq_dict.items():
			rank *= self.counts[ifo+"_snr_chi"][snr, chisq**.5 / snr]
		if rank > self.ranks[-2]:
			rank = self.ranks[-2]
		return rank

	def compute_fap2(self, ifo1, snr1, chisq1, ifo2, snr2, chisq2):
		input = {ifo1:(snr1,chisq1), ifo2:(snr2,chisq2)}
		fap = self.fap_from_rank(self.compute_rank(input))[0]
		fap = 1.0 - (1.0 - fap)**self.trials_factor
		return fap
	
	def compute_fap3(self, ifo1, snr1, chisq1, ifo2, snr2, chisq2, ifo3, snr3, chisq3):
		input = {ifo1:(snr1,chisq1), ifo2:(snr2,chisq2), ifo3:(snr3,chisq3)}
		fap = self.fap_from_rank(self.compute_rank(input))[0]
		fap = 1.0 - (1.0 - fap)**self.trials_factor
		return fap

	def FAR_from_FAP(self, fap, n = 1):
		# the n = 1 case can be done exactly.  That is good since it is
		# the most important.  FIXME it should be possible to code
		# exact solutions for other small values of n that may be
		# imporant once detections are routine :)
		if n == 1:
			return 0. - numpy.log(1. - fap) / self.livetime
		if n > 1 and n <= 100:
			nvec = numpy.linspace(n**2 / 10000., n + 10. * n**.5, 100)
		else:
			nvec = numpy.linspace(n - 10. * n**.5, n + 10. * n**.5, 100)
		FAPS = 1. - poisson.cdf(n,nvec)
		interp = interpolate.interp1d(FAPS, nvec / self.livetime)
		if fap < FAPS[1]:
			return 0.
		if fap > FAPS[-1]:# This means that the FAP has gone off the edge.  We will bump it down because we don't really care about this being right.
			fap = FAPS[-1]
		return interp(fap)[0]

	def compute_far(self, fap, n):
		if fap == 0.0:
			far = 0.
		else:
			far = self.FAR_from_FAP(fap, n)
		return far

def get_ifo_combos_and_live_time(segments, verbose = True):
	#FIXME Kipp will like nothing about this function.
	ifos_available = set(segments.keys())
	ifo_combos = []
	# FIXME is this what we want, H2 never participates in a double?
	# fixme use choices in glue or something for this and then correct the special cases?
	for ifos in [set((u"H1",u"L1")), set((u"H1",u"H2",u"L1")), set((u"H1",u"L1",u"V1")), set((u"H1",u"V1")), set((u"L1",u"V1")), set((u"H1",u"H2",u"L1",u"V1"))]:
		if ifos.issubset(ifos_available):
			ifo_combos.append(ifos)
	
	LTsegs = segments.intersection(ifo_combos[0]).coalesce()
	for ifos in ifo_combos:
		LTsegs |= segments.intersection(ifos).coalesce()
	LTsegs.coalesce()
	livetime =  float(abs(LTsegs))
	if verbose:
		print >> sys.stderr, "Livetime: ", livetime
	# We can never have H1,H2 together
	# FIXME don't use strings as keys, use frozen sets?
	ifo_fap_dict = {"H1,L1":("H1","L1"), "H1,H2,L1":("H1","L1"), "H1,L1,V1":("H1","L1","V1"), "H1,V1":("H1","V1"), "L1,V1":("L1","V1"), "H1,H2,L1,V1":("H1","L1","V1")}
	return ifo_fap_dict, livetime

def two_fap_query(fap_ifos, ifostr):
	query = '''UPDATE coinc_inspiral
	SET false_alarm_rate = (SELECT fap2(snglA.ifo, snglA.snr, snglA.chisq, snglB.ifo, snglB.snr, snglB.chisq)
				FROM coinc_event_map AS mapA ON mapA.coinc_event_id == coinc_inspiral.coinc_event_id
				JOIN coinc_event_map AS mapB ON mapB.coinc_event_id == coinc_inspiral.coinc_event_id
				JOIN sngl_inspiral AS snglA ON snglA.event_id == mapA.event_id
				JOIN sngl_inspiral AS snglB ON snglB.event_id == mapB.event_id
				WHERE snglA.ifo == "%s"
				AND snglB.ifo == "%s")
	WHERE coinc_inspiral.ifos = "%s"''' % (fap_ifos[0], fap_ifos[1], ifostr)
	return query

def three_fap_query(fap_ifos, ifostr):
	query = '''UPDATE coinc_inspiral
	SET false_alarm_rate = (SELECT fap3(snglA.ifo, snglA.snr, snglA.chisq, snglB.ifo, snglB.snr, snglB.chisq, snglC.ifo, snglC.snr, snglC.chisq)
				FROM coinc_event_map AS mapA ON mapA.coinc_event_id == coinc_inspiral.coinc_event_id
				JOIN coinc_event_map AS mapB ON mapB.coinc_event_id == coinc_inspiral.coinc_event_id
				JOIN coinc_event_map AS mapC ON mapC.coinc_event_id == coinc_inspiral.coinc_event_id
				JOIN sngl_inspiral AS snglA ON snglA.event_id == mapA.event_id
				JOIN sngl_inspiral AS snglB ON snglB.event_id == mapB.event_id
				JOIN sngl_inspiral AS snglC ON snglC.event_id == mapC.event_id
				WHERE snglA.ifo == "%s"
				AND snglB.ifo == "%s"
				AND snglC.ifo == "%s")
	WHERE coinc_inspiral.ifos = "%s"''' % (fap_ifos[0], fap_ifos[1], fap_ifos[2], ifostr)
	return query

def fap_query(fap_ifos, ifostr):
	if len(fap_ifos) == 2:
		return two_fap_query(fap_ifos, ifostr)
	if len(fap_ifos) == 3:
		return three_fap_query(fap_ifos, ifostr)
	raise ValueError("number of ifos to compute fap is not supported ", len(fap_ifos))

def parse_command_line():
	parser = OptionParser(
		description = __doc__
	)
	parser.add_option("--background-bins-file", metavar = "filename", action = "append", help = "Set the name of the xml file containing the snr / chisq background distributions")
	parser.add_option("--segments-file", metavar = "filename", help = "Set the name of the xml file containing analysis segments.")
	parser.add_option("--segments-name", metavar = "name", default = "datasegments", help = "Set the name of the analysis segments (default = 'datasegments').")
	parser.add_option("--vetoes-file", metavar = "filename", help = "Set the name of the xml file containing the veto segments.")
	parser.add_option("--vetoes-name", metavar = "name", default = "vetoes", help = "Set the name of the vetoes segments (default = 'vetoes').")
	parser.add_option("--additional-trials-factor", metavar = "int", type="int", default=1, help = "set an additional trials factor to apply to the FAP.  Default = 1 (no trials factor)")
	parser.add_option("--tmp-space", metavar = "dir", help = "Set the name of the tmp space if working with sqlite")
	parser.add_option("--compute-fap", action = "store_true", help = "compute fap, otherwise compute far assuming fap has been calculated")
	parser.add_option("--compute-far", action = "store_true", help = "compute far, only works if fap is being computed or has been computed.")
	parser.add_option("--verbose", "-v", action = "store_true", help = "Be verbose.")

	options, filenames = parser.parse_args()
	return options, filenames

#
# Parse command line
#

options, filenames = parse_command_line()

#
# load segment data
#

segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.segments_file, verbose = options.verbose), options.segments_name).coalesce()
vetoes = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.vetoes_file, verbose = options.verbose), options.vetoes_name).coalesce()

#
# Here we get the union of all of the possible live time segments and subtract
# the vetoes.
#

segments -= vetoes
ifo_fap_dict, livetime = get_ifo_combos_and_live_time(segments)


if options.compute_fap:
	# retrieve rank data
	coincparamsdistributions, likelihood_seglists = gstlal_likelihood.load_likelihood_data(options.background_bins_file, verbose = options.verbose)
	print >>sys.stderr, "smoothing bin counts ..."
	#coincparamsdistributions.finish(filters = gstlal_likelihood.DistributionsStats.filters, verbose = options.verbose)
	# FIXME:  the smoothing should be done with the .finish() method.
	# FIXME:  make sure the smoothing is what is intended:  what's coded here
	# is neither computing a sliding average of bin counts, nor an event rate
	# density.
	# CHAD I have called to_pdf() after smoothing, is that right?
	counts = coincparamsdistributions.background_rates
	for binned_array in counts.values():
		smooth_bins(binned_array)

	print >>sys.stderr, "computing FAP map preliminaries..."
	Far = FAR(livetime, options.additional_trials_factor, counts)
else:
	Far = FAR(livetime, options.additional_trials_factor)
#
# iterate over files to rank
#

for f in filenames:

	from glue.ligolw import dbtables

	working_filename = dbtables.get_connection_filename(f, tmp_path = options.tmp_space, verbose = options.verbose)
	connection = sqlite3.connect(working_filename)

	if options.compute_fap is not None:
		connection.create_function("fap2", 6, Far.compute_fap2)
		connection.create_function("fap3", 9, Far.compute_fap3)
		print >>sys.stderr, "computing faps ..."
		for ifos, in connection.cursor().execute('SELECT DISTINCT(ifos) FROM coinc_inspiral').fetchall():
			print >>sys.stderr, "computing faps for ", ifos
			# FIXME since some combinations are degenerate a few things will be computed twice unecessarily 
			fap_ifos = ifo_fap_dict[ifos]
			Far.updateFAPmap(fap_ifos)
			# FIXME abusing FAR column
			connection.cursor().execute(fap_query(fap_ifos, ifos))
			connection.commit()

	if options.compute_far is not None:
		connection.create_function("far", 2, Far.compute_far)
		ids = [id for id, in connection.cursor().execute("SELECT DISTINCT(time_slide_id) FROM time_slide")]
		for id in ids:
			print >>sys.stderr, "computing rates for ", id
			# FIXME abusing FAR column
			connection.cursor().execute('DROP TABLE IF EXISTS ranktable')
			connection.commit()
			# FIXME any indicies on ranktable??
			connection.cursor().execute('CREATE TEMPORARY TABLE ranktable AS SELECT * FROM coinc_inspiral JOIN coinc_event ON coinc_event.coinc_event_id == coinc_inspiral.coinc_event_id WHERE coinc_event.time_slide_id == ? ORDER BY false_alarm_rate', (id,))
			connection.commit()
			connection.cursor().execute('UPDATE coinc_inspiral SET combined_far = (SELECT far(ranktable.false_alarm_rate, ranktable.rowid) FROM ranktable WHERE ranktable.coinc_event_id == coinc_inspiral.coinc_event_id) WHERE coinc_inspiral.coinc_event_id IN (SELECT coinc_event_id FROM ranktable)')
	
	connection.commit()
	connection.close()
	dbtables.put_connection_filename(f, working_filename, verbose = options.verbose)
