#!/usr/bin/env python
#
# Copyright (C) 2009-2011  Kipp Cannon, Chad Hanna, Drew Keppel
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
"""Stream-based inspiral analysis tool"""


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


import os
import sys
import threading
import warnings
from optparse import OptionParser


# The following snippet is taken from http://gstreamer.freedesktop.org/wiki/FAQ#Mypygstprogramismysteriouslycoredumping.2Chowtofixthis.3F
import pygtk
pygtk.require("2.0")
import gobject
gobject.threads_init()
import pygst
pygst.require("0.10")
import gst


from glue import segments
from glue import segmentsUtils
from glue.ligolw import utils
from glue.ligolw.utils import segments as ligolw_segments
from pylal.datatypes import LIGOTimeGPS
from gstlal import ligolw_output
from gstlal import svd_bank
from gstlal import pipeparts
from gstlal import lloidparts
from gstlal import reference_psd


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#

def parse_banks(bank_string):
	"""
	parses strings of form H1:bank1.xml,H2:bank2.xml,L1:bank3.xml,H2:bank4.xml,...
	"""
	out = {}
	if bank_string is None:
		return out
	for b in bank_string.split(','):
		ifo, bank = b.split(':')
		out.setdefault(ifo, []).append(bank)
	return out

def parse_command_line():
	parser = OptionParser(
		description = __doc__
	)
	parser.add_option("--frame-cache", metavar = "filename", help = "Set the name of the LAL cache listing the LIGO-Virgo .gwf frame files (optional).  This is required unless --fake-data or --online-data is used in which case it must not be set.")
	parser.add_option("--frame-segments-file", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load frame segments (optional).  If this is not provided then all data between --gps-start-time and --gps-end-time will be analyzed.  If this is provided then --frame-segments-name must also be set.")
	parser.add_option("--frame-segments-name", metavar = "name", help = "Set the name of the segments to extract from the segment tables in --frame-segments-file (optional, required if --frame-segments-file is given).")
	parser.add_option("--online-data", action = "store_true", help = "Use online DMT-STRAIN instead of a frame file (optional).")
	parser.add_option("--fake-data", action = "store_true", help = "Instead of reading data from .gwf files, generate and process coloured Gaussian noise modelling the Initial LIGO design spectrum (optional).")
	parser.add_option("--gps-start-time", metavar = "seconds", help = "Set the start time of the frame data to analyze in GPS seconds (required).  Can be specified to nanosecond precision.")
	parser.add_option("--gps-end-time", metavar = "seconds", help = "Set the end time of the frame data to analyze in GPS seconds (required).  Can be specified to nanosecond precision.")
	parser.add_option("--injections", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load injections (optional).")
	parser.add_option("--veto-segments-file", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load vetoes (optional).")
	parser.add_option("--veto-segments-name", metavar = "name", help = "Set the name of the segments to extract from the segment tables and use as the veto list.", default = "vetoes")
	#parser.add_option("--instrument", metavar = "name", help = "Set the name of the instrument to analyze, e.g. \"H1\" (required).")
	parser.add_option("--channel-name", metavar = "name", default = "LSC-STRAIN", help = "Set the name of the channel to process (optional).  The default is \"LSC-STRAIN\".")
	parser.add_option("--flow", metavar = "Hz", type = "float", default = 40.0, help = "Set the template low-frequency cut-off (default = 40.0).")
	parser.add_option("--svd-tolerance", metavar = "match", type = "float", default = 0.9995, help = "Set the SVD reconstruction tolerance (default = 0.9995).")
	parser.add_option("--nxydump-segment", metavar = "start:stop", default = ":", help = "Set the time interval to dump from nxydump elments (optional).  The default is \":\", i.e. dump all time.")
	parser.add_option("--output", metavar = "filename", help = "Set the name of the LIGO light-weight XML output file *.{xml,xml.gz} or an SQLite database *.sqlite (required).")
	parser.add_option("--reference-psd", metavar = "filename", help = "Instead of measuring the noise spectrum, load the spectrum from this LIGO light-weight XML file (optional).")
	parser.add_option("--track-psd", action = "store_true", help = "Track PSD even if a reference is given")
	parser.add_option("--template-bank", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load the template bank for a given instrument in the form ifo:file These can be given as a comma separated list such as H1:file1,H2:file2,L1:file3 to analyze multiple instruments.")
	parser.add_option("--svd-bank", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load the svd bank for a given instrument in the form ifo:file These can be given as a comma separated list such as H1:file1,H2:file2,L1:file3 to analyze multiple instruments.")
	parser.add_option("--time-slide-file", metavar = "filename", help = "Set the name of the xml file to get time slide offsets")
	parser.add_option("--ortho-gate-fap", metavar = "probability", type = "float", default = 1e-2, help = "Set the orthogonal SNR projection gate false-alarm probability (default = 1e-2).")
	parser.add_option("--control-peak-time", metavar = "time", type = "int", help = "Set a time window in seconds to find peaks in the control signal")
	parser.add_option("--ht-gate-threshold", metavar = "threshold", type = "float", help = "Set the threshold on whitened h(t) to mark samples as gaps (glitch removal)")
	parser.add_option("--snr-threshold", metavar = "SNR", type = "float", default = 5.5, help = "Set the SNR threshold (default = 5.5).")
	parser.add_option("--chisq-type", metavar = "type", default = "autochisq", help = "Choose the type of chisq computation to perform. Must be one of (autochisq|timeslicechisq). The default is autochisq.")
	parser.add_option("--coincidence-threshold", metavar = "value", type = "float", default = 0.015, help = "Set the coincidence window in seconds (default = 0.015).  The light-travel time between instruments will be added automatically in the coincidence test.")
	parser.add_option("--write-pipeline", metavar = "filename", help = "Write a DOT graph description of the as-built pipeline to this file (optional).  The environment variable GST_DEBUG_DUMP_DOT_DIR must be set for this option to work.")
	parser.add_option("--write-psd", metavar = "filename", help = "Write measured noise spectrum to this LIGO light-weight XML file (optional).  This option has no effect if --reference-psd is used.")
	parser.add_option("--comment", help = "Set the string to be recorded in comment and tag columns in various places in the output file (optional).")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose (optional).")
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")

	options, filenames = parser.parse_args()

	if len([option for option in ("frame_cache", "fake_data", "online_data") if getattr(options, option) is not None]) != 1:
		raise ValueError, "must provide exactly one of --frame-cache, --fake-data, --online-data"

	required_options = ["output"]
	if options.frame_cache:
		required_options += ["channel_name", "gps_start_time", "gps_end_time"]
	if options.frame_segments_file:
		required_options += ["frame_segments_name"]
	if options.frame_segments_name:
		required_options += ["frame_segments_file"]
	if options.online_data:
		required_options += ["reference_psd"]

	missing_options = []
	if options.template_bank is None and options.svd_bank is None:
		missing_options += ["--template-bank","--svd-bank"]
	missing_options += ["--%s" % option.replace("_", "-") for option in required_options if getattr(options, option) is None]
	if missing_options:
		raise ValueError, "missing required option(s) %s" % ", ".join(sorted(missing_options))

	# Get the banks and make the detectors
	# FIXME add error checking on length of banks per detector, etc
	template_banks = parse_banks(options.template_bank)
	svd_banks = parse_banks(options.svd_bank)
	# FIXME if the channel names are different for different detectors this won't work
	detectors = {}
	for instrument in set(template_banks.keys() + svd_banks.keys()):
		detectors[instrument] = lloidparts.DetectorData(options.frame_cache, options.channel_name)

	# FIXME: should also check for read permissions
	required_files = []
	for instrument in svd_banks:
		required_files.extend(svd_banks[instrument])
	for instrument in template_banks:
		required_files.extend(template_banks[instrument])

	if options.frame_segments_file:
		required_files += [options.frame_segments_file]
	if options.veto_segments_file:
		required_files += [options.veto_segments_file]
	missing_files = [filename for filename in required_files if not os.path.exists(filename)]
	if missing_files:
		raise ValueError, "files %s do not exist" % ", ".join("'%s'" % filename for filename in sorted(missing_files))

	if options.chisq_type not in ["autochisq", "timeslicechisq"]:
		raise ValueError, "--chisq-type must be one of (autochisq|timeslicechisq), given %s" % (options.chisq_type)

	# do this before converting option types
	process_params = ligolw_output.make_process_params(options)

	options.seg = segments.segment(LIGOTimeGPS(options.gps_start_time), LIGOTimeGPS(options.gps_end_time))

	options.nxydump_segment, = segmentsUtils.from_range_strings([options.nxydump_segment], boundtype = LIGOTimeGPS)

	# hard-coded.  this number is needed in a few places, and storing
	# it in with the options is a convenient home
	options.psd_fft_length = 8	# seconds

	return options, filenames, process_params, template_banks, svd_banks, detectors


#
# =============================================================================
#
#                                     Misc
#
# =============================================================================
#


#
# write the pipeline to a dot file.
#


def write_dump_dot(pipeline, filestem, verbose = False):
	"""
	This function needs the environment variable GST_DEBUG_DUMP_DOT_DIR
	to be set.   The filename will be

	os.path.join($GST_DEBUG_DUMP_DOT_DIR, filestem + ".dot")

	If verbose is True, a message will be written to stderr.
	"""
	if "GST_DEBUG_DUMP_DOT_DIR" not in os.environ:
		raise ValueError, "cannot write pipeline, environment variable GST_DEBUG_DUMP_DOT_DIR is not set"
	gst.DEBUG_BIN_TO_DOT_FILE(pipeline, gst.DEBUG_GRAPH_SHOW_ALL, filestem)
	if verbose:
		print >>sys.stderr, "Wrote pipeline to %s" % os.path.join(os.environ["GST_DEBUG_DUMP_DOT_DIR"], "%s.dot" % filestem)


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


#
# parse command line
#


options, filenames, process_params, template_banks, svd_banks, detectors = parse_command_line()


#
# Parse the segments file(s) if provided
#


if options.frame_segments_file is not None:
	frame_segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.frame_segments_file, verbose = options.verbose), options.frame_segments_name).coalesce()
else:
	frame_segments = {}
	for instrument in detectors:
		frame_segments[instrument] = None

if options.veto_segments_file is not None:
	veto_segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.veto_segments_file, verbose = options.verbose), options.veto_segments_name).coalesce()
else:
	veto_segments = None


#
# construct pipeline metadata and measure or retrieve the PSD
#


if options.gps_start_time is None:
	seek_start_type = gst.SEEK_TYPE_NONE
	seek_start_time = -1 # gst.CLOCK_TIME_NONE is exported as unsigned, should have been signed
else:
	seek_start_type = gst.SEEK_TYPE_SET
	seek_start_time = options.seg[0].ns()

if options.gps_end_time is None:
	seek_stop_type = gst.SEEK_TYPE_NONE
	seek_stop_time = -1 # gst.CLOCK_TIME_NONE is exported as unsigned, should have been signed
else:
	seek_stop_type = gst.SEEK_TYPE_SET
	seek_stop_time = options.seg[1].ns()

seekevent = gst.event_new_seek(1.0, gst.Format(gst.FORMAT_TIME),
	gst.SEEK_FLAG_FLUSH | gst.SEEK_FLAG_KEY_UNIT,
	seek_start_type, seek_start_time,
	seek_stop_type, seek_stop_time)


#
# Alright this psd stuff is a bit confusing.  There are two reasons why this
# pipeline could use a reference psd.  One is to apply to the whitener, the
# other is to build the template banks.  In the former case the reference psd
# can be given and it will simply be used as the psd to apply during whitening.
# If a reference psd and --track-psd is given then the reference is the first
# guess, but the whitener does track the psd.  If no reference psd is given and
# we don't want to track the psd then this pipeline will measure a psd in
# advance and use it to whiten the data.  When it comes to templates, if a
# template bank file is given, not an svd bank file, then you need a psd for
# the svd procedure.  If a reference psd is given then it will be used.
# Otherwise the pipeline will measure it.  However if you give a reference psd
# and --track-psd but use a template bank and not an SVD bank then you still
# need to measure a psd in advance for the template bank... 
#


if options.reference_psd is not None:
	psd = reference_psd.read_psd(options.reference_psd, verbose = options.verbose)

elif options.track_psd and not template_banks:
	psd = {}
	if options.track_psd and not template_banks:
		for instrument in detectors:
			psd[instrument] = None
else:
	for instrument in detectors:
		# FIXME right now vetoes are applied after whitening.  If that
		# changes this function will need to know about vetoes too
		psd[instrument] = reference_psd.measure_psd(
			instrument,
			seekevent,
			detectors[instrument],
			options.seg,
			2 * 2048,	# Hz;  must not be less than highest bank fragment sample rate (see below)
			psd_fft_length = options.psd_fft_length,
			fake_data = options.fake_data,
			online_data = options.online_data,
			injection_filename = options.injections,
			frame_segments = frame_segments[instrument],
			verbose = options.verbose
		)
		if options.write_psd is not None:
			reference_psd.write_psd("%s-%s" % (instrument, options.write_psd), psd, instrument=instrument, verbose = options.verbose)

#
# Make template banks
#


banks = {}

for instrument, files in svd_banks.items():
	for filename in files:
		banks.setdefault(instrument,[]).append(svd_bank.read_bank(filename, verbose = options.verbose))

for instrument, files in template_banks.items():
	for filename in files:
		banks.setdefault(instrument,[]).append(svd_bank.build_bank(filename, psd[instrument], options.flow, options.ortho_gate_fap, options.snr_threshold, options.svd_tolerance, verbose = options.verbose))

for instrument in banks:
	for n, bank in enumerate(banks[instrument]):
		bank.logname = "%sbank%d" % (instrument,n)


#
# Build pipeline
#


# If we are using online data, then use a running PSD estimate.
# FIXME: this is a hacky way to set it.  We should give the user direct
# control over this setting.
#FIXME this is busted now that psd is a dict
if options.online_data:
	psd = None


if options.verbose:
	print >>sys.stderr, "assembling pipeline ...",

pipeline = gst.Pipeline("gstlal_inspiral")
mainloop = gobject.MainLoop()
handler = lloidparts.LLOIDHandler(mainloop, pipeline)


triggersrc = lloidparts.mkLLOIDmulti(
	pipeline,
	seekevent,
	detectors = detectors,
	banks = banks,
	psd = psd,
	psd_fft_length = options.psd_fft_length,
	fake_data = options.fake_data,
	online_data = options.online_data,
	injection_filename = options.injections,
	ht_gate_threshold = options.ht_gate_threshold,
	veto_segments = veto_segments,
	verbose = options.verbose,
	nxydump_segment = options.nxydump_segment,
	frame_segments = frame_segments,
	chisq_type = options.chisq_type,
	track_psd = options.track_psd,
	control_peak_time = options.control_peak_time
)


if options.verbose:
	print >>sys.stderr, "done"


#
# build output document
#


if options.verbose:
	print >>sys.stderr, "initializing output document ..."
output = ligolw_output.Data(
	filename = options.output,
	process_params = process_params,
	instruments = set(detectors),
	seg = options.seg,
	out_seg = options.seg, #FIXME make better outseg def?  Maybe pointless now that gstlal inspiral can analyze over frame gaps
	injection_filename = options.injections,
	time_slide_file = options.time_slide_file,
	comment = options.comment,
	tmp_path = options.tmp_space,
	verbose = options.verbose
)
stream_thinca = lloidparts.StreamThinca(
	output,
	coincidence_threshold = options.coincidence_threshold,
	coincidence_back_off = 2 * 5,	# coincidence back-off is twice AppSync dt
	thinca_interval = 50.0	# seconds
)
if options.verbose:
	print >>sys.stderr, "... output document initialized"

if options.verbose:
	print >>sys.stderr, "attaching appsinks to pipeline ...",

appsinks = set()
appsync = pipeparts.AppSync(output, appsink_new_buffer = stream_thinca.appsink_new_buffer, dt = 5)

for pad in triggersrc.src_pads():
	sink = appsync.add_sink(pipeline, pipeparts.mkqueue(pipeline, triggersrc, pad_name = pad.get_property("name")), caps = gst.Caps("application/x-lal-snglinspiral"))
	# FIXME, the pull_appsinks_in_order function works 95% of the time, but
	# the other 5% locks up.  When it is fixed uncomment this line and
	# delete the next line and the branches should be sinked
	sink.connect_after("new-buffer", appsync.pull_appsinks_in_order)
	#sink.connect_after("new-buffer", pipeparts.appsink_new_buffer, output)
	appsinks.add(sink)
if options.verbose:
	print >>sys.stderr, "attached %d, done" % len(appsinks)

if options.write_pipeline is not None:
	#
	# add a signal handler to write a pipeline graph upon receipt of
	# the first trigger buffer.  the caps in the pipeline graph are not
	# fully negotiated until data comes out the end, so this version of
	# the graph shows the final formats on all links
	#

	class AppsinkDumpDotData(object):
		lock = threading.Lock()
		n = 0
		write_after = len(appsinks)
		pipeline = pipeline
		filestem = "%s.%s" % (options.write_pipeline, "TRIGGERS")
		verbose = options.verbose

		def __init__(self):
			self.handler_id = None

		def execute(self):
			self.lock.acquire()
			self.n += 1
			if self.n >= self.write_after:
				write_dump_dot(self.pipeline, self.filestem, verbose = self.verbose)
			self.lock.release()

	def appsink_dump_dot(elem, appsink_dump_dot_data):
		appsink_dump_dot_data.execute()
		elem.disconnect(appsink_dump_dot_data.handler_id)

	for sink in appsinks:
		appsink_dump_dot_data = AppsinkDumpDotData()
		appsink_dump_dot_data.handler_id = sink.connect_after("new-buffer", appsink_dump_dot, appsink_dump_dot_data)


#
# process requested segment
#


if options.write_pipeline is not None:
	write_dump_dot(pipeline, "%s.%s" % (options.write_pipeline, "NULL"), verbose = options.verbose)

if options.verbose:
	print >>sys.stderr, "setting pipeline state to paused ..."
if pipeline.set_state(gst.STATE_PAUSED) != gst.STATE_CHANGE_SUCCESS:
	raise RuntimeError, "pipeline did not enter paused state"

if options.verbose:
	print >>sys.stderr, "setting pipeline state to playing ..."
if pipeline.set_state(gst.STATE_PLAYING) != gst.STATE_CHANGE_SUCCESS:
	raise RuntimeError, "pipeline did not enter playing state"

if options.write_pipeline is not None:
	write_dump_dot(pipeline, "%s.%s" % (options.write_pipeline, "PLAYING"), verbose = options.verbose)

if options.verbose:
	print >>sys.stderr, "running pipeline ..."
mainloop.run()


#
# write output file
#


stream_thinca.flush()
output.write_output_file(verbose = options.verbose)


#
# done
#
