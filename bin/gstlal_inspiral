#!/usr/bin/env python
#
# Copyright (C) 2009-2011  Kipp Cannon, Chad Hanna
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
"""Stream-based inspiral analysis tool"""


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


import os
import sys
import threading
import warnings


import pygtk
pygtk.require('2.0')
import pygst
pygst.require('0.10')
from gstlal.option import OptionParser


from glue import segments
from glue import segmentsUtils
from glue.ligolw import utils
from glue.ligolw.utils import segments as ligolw_segments
from pylal.datatypes import LIGOTimeGPS
from gstlal import ligolw_output
from pylal.xlal.datatypes.snglinspiraltable import from_buffer as sngl_inspirals_from_buffer


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#




def parse_command_line():
	parser = OptionParser(
		description = __doc__
	)
	parser.add_option("--frame-cache", metavar = "filename", help = "Set the name of the LAL cache listing the LIGO-Virgo .gwf frame files (optional).  This is required unless --fake-data or --online-data is used in which case it must not be set.")
	parser.add_option("--online-data", action = "store_true", help = "Use online DMT-STRAIN instead of a frame file (optional).")
	parser.add_option("--fake-data", action = "store_true", help = "Instead of reading data from .gwf files, generate and process coloured Gaussian noise modelling the Initial LIGO design spectrum (optional).")
	parser.add_option("--gps-start-time", metavar = "seconds", help = "Set the start time of the segment to analyze in GPS seconds (required).  Can be specified to nanosecond precision.")
	parser.add_option("--gps-end-time", metavar = "seconds", help = "Set the end time of the segment to analyze in GPS seconds (required).  Can be specified to nanosecond precision.")
	parser.add_option("--injections", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load injections (optional).")
	parser.add_option("--vetoes", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load vetoes (optional).")
	parser.add_option("--veto-segments-name", help = "Set the name of the segments to extract from the segment tables and use as the veto list.", default="vetoes")
	parser.add_option("--instrument", metavar = "name", help = "Set the name of the instrument to analyze, e.g. \"H1\" (required).")
	parser.add_option("--channel-name", metavar = "name", default = "LSC-STRAIN", help = "Set the name of the channel to process (optional).  The default is \"LSC-STRAIN\".")
	parser.add_option("--flow", metavar = "Hz", type = "float", default = 40.0, help = "Set the template low-frequency cut-off (default = 40.0).")
	parser.add_option("--svd-tolerance", metavar = "match", type = "float", default = 0.9995, help = "Set the SVD reconstruction tolerance (default = 0.9995).")
	parser.add_option("--nxydump-segment", metavar = "start:stop", default = ":", help = "Set the time interval to dump from nxydump elments (optional).  The default is \":\", i.e. dump all time.")
	parser.add_option("--output", metavar = "filename", help = "Set the name of the LIGO light-weight XML output file *.{xml,xml.gz} or an SQLite database *.sqlite (required).")
	parser.add_option("--reference-psd", metavar = "filename", help = "Instead of measuring the noise spectrum, load the spectrum from this LIGO light-weight XML file (optional).")
	parser.add_option("--template-bank", metavar = "filename", action = "append", default = [], help = "Set the name of the LIGO light-weight XML file from which to load the template bank (required).  This option can be given multiple times to process multiple template banks in parallel.")
	parser.add_option("--svd-bank", metavar = "filename", action = "append", default = [], help = "Set the name of the LIGO light-weight XML file from which to load the SVD'd template bank (required).  This option can be given multiple times to process multiple template banks in parallel.")
	parser.add_option("--ortho-gate-fap", metavar = "probability", type = "float", default = 1e-2, help = "Set the orthogonal SNR projection gate false-alarm probability (default = 1e-2).")
	parser.add_option("--snr-threshold", metavar = "SNR", type = "float", default = 5.5, help = "Set the SNR threshold (default = 5.5).")
	parser.add_option("--write-pipeline", metavar = "filename", help = "Write a DOT graph description of the as-built pipeline to this file (optional).  The environment variable GST_DEBUG_DUMP_DOT_DIR must be set for this option to work.")
	parser.add_option("--write-psd", metavar = "filename", help = "Write measured noise spectrum to this LIGO light-weight XML file (optional).  This option has no effect if --reference-psd is used.")
	parser.add_option("--comment", help = "Set the string to be recorded in comment and tag columns in various places in the output file (optional).")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose (optional).")
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")

	# FIXME: This will only raise an exception if we have pygobject < 2.16.
	# Can we bumpy our pygobject dependency version to 2.16?
	try:
		import gstoption
		parser.add_option_group(gstoption.get_group())
	except:
		warnings.warn("failed to get GStreamer's option group, not adding command line options for it")

	options, filenames = parser.parse_args()

	if len([option for option in ('frame_cache', 'fake_data', 'online_data') if getattr(options, option) is not None]) != 1:
		raise ValueError, "must provide exactly one of --frame-cache, --fake-data, --online-data"

	required_options = ["instrument", "output"]
	if options.frame_cache:
		required_options += ["channel_name", "gps_start_time", "gps_end_time"]
	if options.online_data:
		required_options += ["reference_psd"]

	missing_options = []
	if len(options.template_bank) + len(options.svd_bank) == 0:
		missing_options += ["--template-bank or --svd-bank"]
	missing_options += ["--%s" % option.replace("_", "-") for option in required_options if getattr(options, option) is None]
	if missing_options:
		raise ValueError, "missing required option(s) %s" % ", ".join(sorted(missing_options))

	# FIXME: should also check for read permissions
	missing_files = [filename for filename in options.template_bank + options.svd_bank if not os.path.exists(filename)]
	if missing_files:
		raise ValueError, "files %s do not exist" % ", ".join("'%s'" % filename for filename in sorted(missing_files))

	# do this before converting option types
	process_params = ligolw_output.make_process_params(options)

	options.seg = segments.segment(LIGOTimeGPS(options.gps_start_time), LIGOTimeGPS(options.gps_end_time))

	options.nxydump_segment, = segmentsUtils.from_range_strings([options.nxydump_segment], boundtype = LIGOTimeGPS)

	# hard-coded.  this number is needed in a few places, and storing
	# it in with the options is a convenient home
	options.psd_fft_length = 8	# seconds

	return options, filenames, process_params


#
# =============================================================================
#
#                                     Misc
#
# =============================================================================
#


#
# write the pipeline to a dot file.
#


def write_dump_dot(pipeline, filestem, verbose = False):
	"""
	This function needs the environment variable GST_DEBUG_DUMP_DOT_DIR
	to be set.   The filename will be

	os.path.join($GST_DEBUG_DUMP_DOT_DIR, filestem + ".dot")

	If verbose is True, a message will be written to stderr.
	"""
	if "GST_DEBUG_DUMP_DOT_DIR" not in os.environ:
		raise ValueError, "cannot write pipeline, environment variable GST_DEBUG_DUMP_DOT_DIR is not set"
	gst.DEBUG_BIN_TO_DOT_FILE(pipeline, gst.DEBUG_GRAPH_SHOW_ALL, filestem)
	if verbose:
		print >>sys.stderr, "Wrote pipeline to %s" % os.path.join(os.environ["GST_DEBUG_DUMP_DOT_DIR"], "%s.dot" % filestem)


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


#
# parse command line
#


options, filenames, process_params = parse_command_line()


#
# Parse the veto file into segments if provided
#


if options.vetoes is not None:
	veto_segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.vetoes), options.veto_segments_name).coalesce()
else:
	veto_segments = None


#
# Import everything that depends on GStreamer
#


# The following snippet is taken from http://gstreamer.freedesktop.org/wiki/FAQ#Mypygstprogramismysteriouslycoredumping.2Chowtofixthis.3F
import pygtk
pygtk.require("2.0")
import gobject
gobject.threads_init()
import pygst
pygst.require('0.10')
import gst


from gstlal import pipeparts
from gstlal import lloidparts
from gstlal import templates
from gstlal import svd_bank
from gstlal import reference_psd


#
# construct pipeline metadata and measure or retrieve the PSD
#


if options.gps_start_time is None:
	seek_start_type = gst.SEEK_TYPE_NONE
	seek_start_time = -1 # gst.CLOCK_TIME_NONE is exported as unsigned, should have been signed
else:
	seek_start_type = gst.SEEK_TYPE_SET
	seek_start_time = options.seg[0].ns()

if options.gps_end_time is None:
	seek_stop_type = gst.SEEK_TYPE_NONE
	seek_stop_time = -1 # gst.CLOCK_TIME_NONE is exported as unsigned, should have been signed
else:
	seek_stop_type = gst.SEEK_TYPE_SET
	seek_stop_time = options.seg[1].ns()

seekevent = gst.event_new_seek(1.0, gst.Format(gst.FORMAT_TIME),
	gst.SEEK_FLAG_FLUSH | gst.SEEK_FLAG_KEY_UNIT,
	seek_start_type, seek_start_time,
	seek_stop_type, seek_stop_time)


detectors = {
	options.instrument: lloidparts.DetectorData(options.frame_cache, options.channel_name)
}


if options.reference_psd is not None:
	psd = reference_psd.read_psd(options.reference_psd, verbose = options.verbose)
else:
	# FIXME right now vetoes are applied after whitening.  If that
	# changes this function will need to know about vetoes too
	psd = measure_psd(
		options.instrument,
		seekevent,
		detectors[options.instrument],
		options.seg,
		2 * 2048,	# Hz;  must not be less than highest bank fragment sample rate (see below)
		psd_fft_length = options.psd_fft_length,
		fake_data = options.fake_data,
		online_data = options.online_data,
		injection_filename = options.injections,
		verbose = options.verbose
	)
	if options.write_psd is not None:
		write_psd(options.write_psd, psd, verbose = options.verbose)


#
# Make template banks
#


banks = []
for filename in options.template_bank:
	banks.append(svd_bank.build_bank(filename, psd, options.flow, options.ortho_gate_fap, options.snr_threshold, options.svd_tolerance, verbose = options.verbose))
for filename in options.svd_bank:
	banks.append(svd_bank.read_bank(filename))

for n, bank in enumerate(banks):
	bank.logname = "bank%d" % n


#
# Build pipeline
#


# If we are using online data, then use a running PSD estimate.
# FIXME: this is a hacky way to set it.  We should give the user direct
# control over this setting.
if options.online_data:
	psd = None


pipeline = gst.Pipeline("gstlal_inspiral")
mainloop = gobject.MainLoop()
handler = lloidparts.LLOIDHandler(mainloop, pipeline)


triggersrc = lloidparts.mkLLOIDmulti(
	pipeline,
	seekevent,
	detectors = detectors,
	banks = banks,
	psd = psd,
	psd_fft_length = options.psd_fft_length,
	fake_data = options.fake_data,
	online_data = options.online_data,
	injection_filename = options.injections,
	veto_segments = veto_segments,
	verbose = options.verbose,
	nxydump_segment = options.nxydump_segment
)


#
# build output document
#


options.out_seg = segments.segment(options.seg[0]+max([b.filter_length for b in banks]), options.seg[1]) #FIXME make better outseg def.
output = ligolw_output.Data(
	filename = options.output,
	process_params = process_params,
	ifos = set(detectors),
	seg = options.seg,
	out_seg = options.out_seg,
	injection_filename = options.injections,
	comment = options.comment,
	tmp_path = options.tmp_space,
	verbose = options.verbose
)


def appsink_new_buffer(elem, output):
	output.lock.acquire()
	for row in sngl_inspirals_from_buffer(elem.emit("pull-buffer")):
		if (row.end_time + 1e-9*row.end_time_ns) in output.out_seg:
			row.process_id = output.process.process_id
			row.event_id = output.sngl_inspiral_table.get_next_id()
			output.sngl_inspiral_table.append(row)
	if output.connection is not None:
		output.connection.commit()
	output.lock.release()


appsinks = set()
for pad in triggersrc.src_pads():
	sink = pipeparts.mkappsink(pipeline, triggersrc, pad = pad, caps = gst.Caps("application/x-lal-snglinspiral"))
	sink.connect_after("new-buffer", appsink_new_buffer, output)
	appsinks.add(sink)


if options.write_pipeline is not None:
	#
	# add a signal handler to write a pipeline graph upon receipt of
	# the first trigger buffer.  the caps in the pipeline graph are not
	# fully negotiated until data comes out the end, so this version of
	# the graph shows the final formats on all links
	#

	class AppsinkDumpDotData(object):
		lock = threading.Lock()
		n = 0
		write_after = len(appsinks)
		pipeline = pipeline
		filestem = "%s.%s" % (options.write_pipeline, "TRIGGERS")
		verbose = options.verbose

		def __init__(self):
			self.handler_id = None

		def execute(self):
			self.lock.acquire()
			self.n += 1
			if self.n >= self.write_after:
				write_dump_dot(self.pipeline, self.filestem, verbose = self.verbose)
			self.lock.release()

	def appsink_dump_dot(elem, appsink_dump_dot_data):
		appsink_dump_dot_data.execute()
		elem.disconnect(appsink_dump_dot_data.handler_id)

	for sink in appsinks:
		appsink_dump_dot_data = AppsinkDumpDotData()
		appsink_dump_dot_data.handler_id = sink.connect_after("new-buffer", appsink_dump_dot, appsink_dump_dot_data)


#
# process requested segment
#


if options.write_pipeline is not None:
	write_dump_dot(pipeline, "%s.%s" % (options.write_pipeline, "NULL"), verbose = options.verbose)
pipeline.set_state(gst.STATE_PLAYING)
if options.write_pipeline is not None:
	write_dump_dot(pipeline, "%s.%s" % (options.write_pipeline, "PLAYING"), verbose = options.verbose)
mainloop.run()


#
# write output file
#


output.write_output_file(verbose = options.verbose)


#
# done
#
